<!doctype html><html lang=ko dir=ltr class="blog-wrapper blog-authors-posts-page plugin-blog plugin-id-default" data-has-hydrated=false><head><meta charset=UTF-8><meta name=generator content="Docusaurus v3.9.2"><title data-rh=true>Eunkwang Shin - 898개 게시물 | gracefullight.dev</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"/><meta data-rh=true name=twitter:card content=summary_large_image /><meta data-rh=true property=og:url content=https://gracefullight.dev/authors/me/authors/9/ /><meta data-rh=true property=og:locale content=ko /><meta data-rh=true property=og:locale:alternate content=en /><meta data-rh=true name=docusaurus_locale content=ko /><meta data-rh=true name=docsearch:language content=ko /><meta data-rh=true content=gcY9SiftHgQoJjBZ7IgwNNN5_atLPAX6kWb1nFVfa6E name=google-site-verification /><meta data-rh=true content=65AD1E28C0D057CEB3C68FBC0293E55B name=msvalidate.01 /><meta data-rh=true content=d024c2837887f72dc7b3792b958be74d69ba9593 name=naver-site-verification /><meta data-rh=true content=f7c93483a6f87c79 name=yandex-verification /><meta data-rh=true content=yZEdU1ABcR name=baidu-site-verification /><meta data-rh=true content=uelupjqqsm5egzlhy1aev2rfxow5yt name=facebook-domain-verification /><meta data-rh=true property=og:title content="Eunkwang Shin - 898개 게시물 | gracefullight.dev"/><meta data-rh=true name=docusaurus_tag content=blog_authors_posts /><meta data-rh=true name=docsearch:docusaurus_tag content=blog_authors_posts /><link data-rh=true rel=icon href=/img/favicon.ico /><link data-rh=true rel=canonical href=https://gracefullight.dev/authors/me/authors/9/ /><link data-rh=true rel=alternate href=https://gracefullight.dev/authors/me/authors/9/ hreflang=ko /><link data-rh=true rel=alternate href=https://gracefullight.dev/en/authors/me/authors/9/ hreflang=en /><link data-rh=true rel=alternate href=https://gracefullight.dev/authors/me/authors/9/ hreflang=x-default /><link data-rh=true rel=preconnect href=https://RFS69RSYOJ-dsn.algolia.net crossorigin=anonymous /><link rel=alternate type=application/rss+xml href=/rss.xml title="gracefullight.dev RSS Feed"><link rel=alternate type=application/atom+xml href=/atom.xml title="gracefullight.dev Atom Feed"><link rel=alternate type=application/json href=/feed.json title="gracefullight.dev JSON Feed"><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=G-E99DNE7S05"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-E99DNE7S05",{})</script><link rel=search type=application/opensearchdescription+xml title=gracefullight.dev href=/opensearch.xml><link href=/img/favicon-32x32.png rel=icon><link href=/manifest.json rel=manifest><meta content=#f28913 name=theme-color><meta content=yes name=mobile-web-app-capable><meta content=#f28913 name=apple-mobile-web-app-status-bar-style><link href=/img/apple-touch-icon.png rel=apple-touch-icon><link rel=preconnect href=https://pagead2.googlesyndication.com><script src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3004788392777865" async crossorigin=anonymous></script><link rel=preconnect href=https://www.clarity.ms><script>!function(t,e,n,a,c,i,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(i=e.createElement(a)).async=1,i.src="https://www.clarity.ms/tag/"+c,(r=e.getElementsByTagName(a)[0]).parentNode.insertBefore(i,r)}(window,document,"clarity","script","aongv9xgi6")</script><link rel=preconnect href=https://wcs.naver.net><script src=https://wcs.naver.net/wcslog.js async></script><script>if(!wcs_add)var wcs_add={};wcs_add.wa="156bc73a81e3bd0",window.wcs&&wcs_do()</script><link rel=preconnect href=https://cdn.channel.io><script>!function(){var n=window;if(n.ChannelIO)return(window.console.error||window.console.log||function(){})("ChannelIO script included twice.");var e=function(){e.c(arguments)};function t(){if(!n.ChannelIOInitialized){n.ChannelIOInitialized=!0;var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="https://cdn.channel.io/plugin/ch-plugin-web.js",e.charset="UTF-8";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}}e.q=[],e.c=function(n){e.q.push(n)},n.ChannelIO=e,"complete"===document.readyState?t():window.attachEvent?window.attachEvent("onload",t):(window.addEventListener("DOMContentLoaded",t,!1),window.addEventListener("load",t,!1))}(),ChannelIO("boot",{pluginKey:"0fd130ba-a1a6-4b7e-802a-e82a885a7fd8"})</script><link rel=preconnect href=https://static.cloudflareinsights.com><script src=https://static.cloudflareinsights.com/beacon.min.js defer data-cf-beacon='{"token":"c0899829e72b45e98dff77241127252c"}'></script><link href=https://mc.yandex.ru rel=preconnect><script>!function(e,t,c,n,r,a,s){e[r]=e[r]||function(){(e[r].a=e[r].a||[]).push(arguments)},e[r].l=+new Date;for(var i=0;i<document.scripts.length;i++)if(document.scripts[i].src===n)return;a=t.createElement(c),s=t.getElementsByTagName(c)[0],a.async=1,a.src=n,s.parentNode.insertBefore(a,s)}(window,document,"script","https://mc.yandex.ru/metrika/tag.js?id=104072655","ym"),ym(0x63405cf,"init",{ssr:!0,clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!1})</script><link href=https://cdn.jsdelivr.net rel=preconnect><script type=application/ld+json>{"@context":"http://schema.org","@type":"Person","email":"mailto:gracefullight.dev@gmail.com","image":"https://avatars.githubusercontent.com/u/11773683?v=4","jobTitle":"FullStack JavaScript Developer","logo":"https://gracefullight.dev/img/apple-touch-icon.png","name":"Eunkwang Shin","nationality":"Korean","sameAs":["https://github.com/gracefullight","https://linkedin.com/in/gracefullight"],"url":"https://gracefullight.dev"}</script><link rel=stylesheet crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css type=text/css><link rel=stylesheet href=/assets/css/styles.775e2857.css /><script src=/assets/js/runtime~main.8c99d553.js defer></script><script src=/assets/js/main.55b7c064.js defer></script></head><body class=navigation-with-keyboard><svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><link rel=preload as=image href=/img/favicon-32x32.png /><link rel=preload as=image href="https://avatars.githubusercontent.com/u/11773683?v=4"/><div role=region aria-label="본문으로 건너뛰기"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>본문으로 건너뛰기</a></div><nav aria-label=Main class="theme-layout-navbar navbar navbar--fixed-top"><div class=navbar__inner><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><div class=navbar__logo><img src=/img/favicon-32x32.png alt="gracefullight.dev blog logo" class="themedComponent_mlkZ themedComponent--light_NVdE"/><img src=/img/favicon-32x32.png alt="gracefullight.dev blog logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"/></div><b class="navbar__title text--truncate">gracefullight.dev</b></a><div class="navbar__item dropdown dropdown--hoverable"><a href=# aria-haspopup=true aria-expanded=false role=button class=navbar__link><svg viewBox="0 0 24 24" width=20 height=20 aria-hidden=true class=iconLanguage_nlXk><path fill=currentColor d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>한국어</a><ul class=dropdown__menu><li><a href=/authors/me/authors/9/ target=_self rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang=ko>한국어</a><li><a href=/en/authors/me/authors/9/ target=_self rel="noopener noreferrer" class=dropdown__link lang=en>English</a></ul></div><a class="navbar__item navbar__link" href=/archive/>Archives</a><a class="navbar__item navbar__link" href=/tags/>Tags</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href=https://github.com/gracefullight target=_blank rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type=button disabled title="system mode" aria-label="어두운 모드와 밝은 모드 전환하기 (현재 system mode)"><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill=currentColor d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"/></svg><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill=currentColor d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"/></svg><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill=currentColor d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"/></svg></button></div><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="검색 (Meta+k)" aria-keyshortcuts=Meta+k><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 24 24" aria-hidden=true><circle cx=11 cy=11 r=8 stroke=currentColor fill=none stroke-width=1.4 /><path d="m21 21-4.3-4.3" stroke=currentColor fill=none stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>검색</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class=row><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="최근 블로그 문서 둘러보기"><div class="sidebarItemTitle_pO2u margin-bottom--md">최근 포스트</div><div role=group><h3 class=yearGroupHeading_rMGB>2026</h3><ul class="sidebarItemList_Yudw clean-list"><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/2026/02/27/free-up-storage-space-on-mac/>Free up storage space on mac</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/2026/02/27/promoting-an-opensource-project/>Promoting an opensource project</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/2026/02/24/iqc-002/>IQC 002</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/2026/02/23/tim-002/>TIM 002</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/2026/02/17/innovation-tactics/>Innovation Tactics</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/2026/01/31/agentic-sdlc/>Agentic SDLC</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/2026/01/29/local-docker-env/>로컬 도커 환경 툴 비교</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/vocab/phrasal-verbs-01/>Phrasal Verbs 01</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/vocab/phrasal-verbs-014/>Phrasal Verbs 014</a><li class=sidebarItem__DBe><a class=sidebarItemLink_mo7H href=/vocab/phrasal-verbs-013/>Phrasal Verbs 013</a></ul></div></nav></aside><main class="col col--7"><header class=margin-bottom--xl><div class="avatar margin-bottom--sm author-as-h1_n9oJ"><a class=avatar__photo-link href=/authors/me/><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/11773683?v=4" alt="Eunkwang Shin"/></a><div class="avatar__intro authorDetails_lV9A"><div class=avatar__name><a href=/authors/me/><h1 class=authorName_yefp translate=no>Eunkwang Shin</h1></a></div><small class=authorTitle_nd0D title=Owner>Owner</small><div class=authorSocials_rSDt><a href=https://www.linkedin.com/in/gracefullight/ target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=LinkedIn><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em preserveAspectRatio=xMidYMid viewBox="0 0 256 256" style=--dark:#0a66c2;--light:#ffffffe6 class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"/></svg></a><a href=https://github.com/gracefullight target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=GitHub><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em viewBox="0 0 256 250" preserveAspectRatio=xMidYMid style=--dark:#000;--light:#fff class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"/></svg></a><a href=mailto:gracefullight.dev@gmail.com target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=Email><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 24 24" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 class=authorSocialIcon_XYv3><path stroke=none d="M0 0h24v24H0z"/><path d="M7.2 12a4.8 4.8 0 1 0 9.6 0 4.8 4.8 0 1 0-9.6 0"/><path d="M16.8 12v1.8a3 3 0 0 0 6 0V12a10.8 10.8 0 1 0-6.6 9.936"/></svg></a></div></div></div><p>Full Stack JavaScript Developer | Half-time Open Sourcerer.</p><a href=/authors/>모든 저자 보기</a></header><hr/><article class=margin-bottom--xl><header><h2 class=title_f1Hy><a href=/2025/08/21/CLIPort-review/>CLIPort Review</a></h2><div class="container_mt6G margin-vert--md"><time datetime=2025-08-21T13:02:02.850Z>2025년 8월 21일</time> · <!-- -->약 2분</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class=avatar__photo-link href=/authors/me/><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/11773683?v=4" alt="Eunkwang Shin"/></a><div class="avatar__intro authorDetails_lV9A"><div class=avatar__name><a href=/authors/me/><span class=authorName_yefp translate=no>Eunkwang Shin</span></a></div><small class=authorTitle_nd0D title=Owner>Owner</small><div class=authorSocials_rSDt><a href=https://www.linkedin.com/in/gracefullight/ target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=LinkedIn><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em preserveAspectRatio=xMidYMid viewBox="0 0 256 256" style=--dark:#0a66c2;--light:#ffffffe6 class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"/></svg></a><a href=https://github.com/gracefullight target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=GitHub><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em viewBox="0 0 256 250" preserveAspectRatio=xMidYMid style=--dark:#000;--light:#fff class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"/></svg></a><a href=mailto:gracefullight.dev@gmail.com target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=Email><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 24 24" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 class=authorSocialIcon_XYv3><path stroke=none d="M0 0h24v24H0z"/><path d="M7.2 12a4.8 4.8 0 1 0 9.6 0 4.8 4.8 0 1 0-9.6 0"/><path d="M16.8 12v1.8a3 3 0 0 0 6 0V12a10.8 10.8 0 1 0-6.6 9.936"/></svg></a></div></div></div></div></div></header><div class=markdown><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=key-idea>Key Idea<a href=#key-idea class=hash-link aria-label="Key Idea에 대한 직접 링크" title="Key Idea에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">CLIPort proposes a <strong>two-stream architecture</strong> for vision-based manipulation:<!-- -->
<ul>
<li class=""><strong>Semantic pathway (what):</strong> leverages CLIP for broad semantic understanding.</li>
<li class=""><strong>Spatial pathway (where):</strong> leverages Transporter for fine-grained spatial reasoning.</li>
</ul>
</li>
<li class="">This design is <strong>inspired by the two-stream hypothesis in cognitive psychology</strong> (ventral/dorsal pathways).</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=framework-contributions>Framework Contributions<a href=#framework-contributions class=hash-link aria-label="Framework Contributions에 대한 직접 링크" title="Framework Contributions에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class=""><strong>Benchmark Extension:</strong> Expanded the Ravens benchmark with language-grounding tasks for manipulation.</li>
<li class=""><strong>Two-Stream Architecture:</strong> Uses pre-trained vision-language models (CLIP) to condition precise manipulation policies with language goals.</li>
<li class=""><strong>Empirical Results:</strong> Demonstrates robustness on diverse manipulation tasks, including multi-task settings and real-robot experiments.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=architectural-design>Architectural Design<a href=#architectural-design class=hash-link aria-label="Architectural Design에 대한 직접 링크" title="Architectural Design에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">CLIPort integrates <strong>semantic (CLIP)</strong> with <strong>spatial (Transporter)</strong> features by lateral fusion.</li>
<li class="">The semantic stream is conditioned with <strong>language features from CLIP’s text encoder</strong> and fused with intermediate spatial features.</li>
<li class="">Enables <strong>end-to-end learning of affordance predictions</strong> (pick-and-place) without explicit object models, segmentations, or symbolic states.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=key-insights>Key Insights<a href=#key-insights class=hash-link aria-label="Key Insights에 대한 직접 링크" title="Key Insights에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Formulates manipulation as <strong>action detection</strong> (where to act), instead of object detection.</li>
<li class=""><strong>Tabula rasa systems</strong> (like plain Transporter) require new demonstrations for every goal/task. CLIPort addresses this with a <strong>strong semantic prior</strong> (from CLIP) to generalize across tasks and concepts.</li>
<li class=""><strong>Language-conditioned policies</strong> provide an intuitive interface for specifying goals and transferring concepts.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=experimental-results>Experimental Results<a href=#experimental-results class=hash-link aria-label="Experimental Results에 대한 직접 링크" title="Experimental Results에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class=""><strong>Simulation (PyBullet, UR5 robot with suction gripper):</strong>
<ul>
<li class="">10 language-conditioned tasks with thousands of unique instances.</li>
<li class="">Multi-task CLIPort outperformed or matched single-task models, even with fewer demonstrations.</li>
<li class="">CLIP-only or Transporter-only baselines saturate, while CLIPort exceeds 90% success with just 100 demos.</li>
</ul>
</li>
<li class=""><strong>Generalization:</strong>
<ul>
<li class="">CLIPort generalizes to <strong>unseen attributes</strong> (e.g., new colors, shapes, object categories).</li>
<li class="">Struggles with <strong>completely novel attributes</strong> (e.g., “pink” or “orange” never seen in training).</li>
</ul>
</li>
<li class=""><strong>Real-World Robot Experiments (Franka Panda):</strong>
<ul>
<li class="">Achieved ~70% success on real tasks with just 179 demonstrations.</li>
<li class="">Performance trends were consistent with simulation, validating sim-to-real transfer.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=conclusion>Conclusion<a href=#conclusion class=hash-link aria-label="Conclusion에 대한 직접 링크" title="Conclusion에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">CLIPort shows that <strong>multi-task, language-conditioned policies</strong> generalize across tasks better than object-centric or tabula rasa methods.</li>
<li class="">With <strong>action abstraction</strong> and <strong>spatio-semantic priors</strong>, end-to-end models can learn new skills <strong>without requiring hand-engineered pipelines</strong>.</li>
<li class="">Limitations remain for <strong>dexterous 6-DoF manipulation</strong> and complex continuous control.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=ref>Ref<a href=#ref class=hash-link aria-label="Ref에 대한 직접 링크" title="Ref에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Shridhar, M., Manuelli, L., & Fox, D. (2022). Cliport: What and where pathways for robotic manipulation. Conference on robot learning.</li>
</ul></div><footer class="row docusaurus-mt-lg"><div class=col><b>태그:</b><ul class="tags_jXut padding--none margin-left--sm"><li class=tag_QGVx><a rel=tag title="Vision-Language Models" class="tag_zVej tagRegular_sFm0" href=/tags/vlm/>vlm</a></ul></div></footer></article><article class=margin-bottom--xl><header><h2 class=title_f1Hy><a href=/2025/08/18/mitigating-hallucinations-on-object-attributesusing-multiview-images-review/>Mitigating Hallucinations on Object Attributes Review</a></h2><div class="container_mt6G margin-vert--md"><time datetime=2025-08-18T05:44:39.579Z>2025년 8월 18일</time> · <!-- -->약 4분</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class=avatar__photo-link href=/authors/me/><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/11773683?v=4" alt="Eunkwang Shin"/></a><div class="avatar__intro authorDetails_lV9A"><div class=avatar__name><a href=/authors/me/><span class=authorName_yefp translate=no>Eunkwang Shin</span></a></div><small class=authorTitle_nd0D title=Owner>Owner</small><div class=authorSocials_rSDt><a href=https://www.linkedin.com/in/gracefullight/ target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=LinkedIn><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em preserveAspectRatio=xMidYMid viewBox="0 0 256 256" style=--dark:#0a66c2;--light:#ffffffe6 class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"/></svg></a><a href=https://github.com/gracefullight target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=GitHub><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em viewBox="0 0 256 250" preserveAspectRatio=xMidYMid style=--dark:#000;--light:#fff class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"/></svg></a><a href=mailto:gracefullight.dev@gmail.com target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=Email><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 24 24" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 class=authorSocialIcon_XYv3><path stroke=none d="M0 0h24v24H0z"/><path d="M7.2 12a4.8 4.8 0 1 0 9.6 0 4.8 4.8 0 1 0-9.6 0"/><path d="M16.8 12v1.8a3 3 0 0 0 6 0V12a10.8 10.8 0 1 0-6.6 9.936"/></svg></a></div></div></div></div></div></header><div class=markdown><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=overview>Overview<a href=#overview class=hash-link aria-label="Overview에 대한 직접 링크" title="Overview에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Introduces a <strong>HoOA benchmark</strong> that isolates hallucinations on <strong>object attributes</strong> (color, shape) from existence/relationship errors.</li>
<li class="">Proposes <strong>MIAVLM</strong>: leverages <strong>multiview images</strong> (generated from a single image’s 3D representation) and a <strong>Multiview Attributes Perceiver (MAP)</strong> to make fusion <strong>order-invariant</strong>.</li>
<li class="">Adds <strong>negative instructions</strong> during tuning to counter LVLMs’ tendency to answer "Yes".</li>
<li class="">Results: best HoOA metric (<strong>0.775 / 0.787</strong>) with <strong>fastest inference</strong> (<strong>0.071 / 0.105 s</strong>). "9in1" tiling is ineffective; separate multiview inputs help.</li>
<li class="">Training: LM loss, Adam (lr=0.001), cosine annealing, 20 epochs, single NVIDIA 3090.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=hallucinations-on-object-attributes-hooa>Hallucinations on Object Attributes (HoOA)<a href=#hallucinations-on-object-attributes-hooa class=hash-link aria-label="Hallucinations on Object Attributes (HoOA)에 대한 직접 링크" title="Hallucinations on Object Attributes (HoOA)에 대한 직접 링크" translate=no>​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=issues>Issues<a href=#issues class=hash-link aria-label="Issues에 대한 직접 링크" title="Issues에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">HoOA = incorrect attribute descriptions for existing objects (distinct from HoOE/HoOR).</li>
<li class="">Root causes analyzed:<!-- -->
<ul>
<li class=""><strong>Single-view insufficiency</strong>: fine-grained details can be invisible from a single viewpoint.</li>
<li class=""><strong>Instruction bias</strong>: overexposure to positive/affirmative patterns → "Yes" bias.</li>
<li class=""><strong>Order sensitivity</strong>: multi-image inputs change predictions when view order changes.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=mitigation-methods-this-paper>Mitigation Methods (this paper)<a href=#mitigation-methods-this-paper class=hash-link aria-label="Mitigation Methods (this paper)에 대한 직접 링크" title="Mitigation Methods (this paper)에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class=""><strong>Multiview prompts</strong>: sample views from a single image’s 3D reconstruction to recover missed details.</li>
<li class=""><strong>MAP (order-invariant fusion)</strong>: learn view weights and fuse per-view features via <strong>weighted sum</strong>; input order has no effect; supports any number of views.</li>
<li class=""><strong>Negative instructions</strong>: incorporate "No"-answerable questions in tuning to suppress "Yes" bias.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=benchmark-hooa>Benchmark (HoOA)<a href=#benchmark-hooa class=hash-link aria-label="Benchmark (HoOA)에 대한 직접 링크" title="Benchmark (HoOA)에 대한 직접 링크" translate=no>​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=construction>Construction<a href=#construction class=hash-link aria-label="Construction에 대한 직접 링크" title="Construction에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Based on <strong>CelebAText-HQ</strong>; manual attribute descriptions rewritten into <strong>Yes/No</strong> questions.<!-- -->
<ul>
<li class=""><strong>Positive questions</strong> → correct answer "Yes".</li>
<li class=""><strong>Negative questions</strong> → attribute flipped/opposite → correct answer "No" (to expose "Yes" bias).</li>
</ul>
</li>
<li class="">Scale: 1,430 images, 14,291 positive + 14,291 negative questions.</li>
<li class="">Split: <strong>9:1</strong> train<!-- -->:test<!-- -->.</li>
<li class=""><strong>Metric</strong>: average of accuracy on positive and negative questions (balanced HoOA score).</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=model-miavlm>Model: MIAVLM<a href=#model-miavlm class=hash-link aria-label="Model: MIAVLM에 대한 직접 링크" title="Model: MIAVLM에 대한 직접 링크" translate=no>​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=visual-extractor-ve>Visual Extractor (VE)<a href=#visual-extractor-ve class=hash-link aria-label="Visual Extractor (VE)에 대한 직접 링크" title="Visual Extractor (VE)에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">6 stacked Transformer <strong>decoder</strong> blocks.</li>
<li class=""><strong>Soft prompts <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>P</mi><mo>∈</mo><msup><mi mathvariant=double-struck>R</mi><mrow><mi>l</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding=application/x-tex>P \in \mathbb{R}^{l \times d}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7224em;vertical-align:-0.0391em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.8491em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8491em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></strong> are <strong>queries</strong>; <strong>image embeddings <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>e_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">e</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span></span></span></span></strong> are <strong>keys/values</strong>.</li>
<li class="">Per-view cross-attention computed <strong>in parallel</strong> (no autoregressive chaining; no assumed order).</li>
<li class="">Per-view output:<!-- -->
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>o</mi><mi>i</mi></msub><mo>=</mo><mrow><mi mathvariant=normal>s</mi><mi mathvariant=normal>o</mi><mi mathvariant=normal>f</mi><mi mathvariant=normal>t</mi><mi mathvariant=normal>m</mi><mi mathvariant=normal>a</mi><mi mathvariant=normal>x</mi></mrow><mtext> ⁣</mtext><mrow><mo fence=true>(</mo><mfrac><mrow><mo stretchy=false>(</mo><mi>P</mi><msub><mi>W</mi><mi>Q</mi></msub><mo stretchy=false>)</mo><mo stretchy=false>(</mo><msub><mi>e</mi><mi>i</mi></msub><msub><mi>W</mi><mi>K</mi></msub><msup><mo stretchy=false>)</mo><mi mathvariant=normal>⊤</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo fence=true>)</mo></mrow><msub><mi>e</mi><mi>i</mi></msub><msub><mi>W</mi><mi>V</mi></msub><mo separator=true>,</mo><mspace width=1em /><msub><mi>O</mi><mrow><mi>V</mi><mi>E</mi></mrow></msub><mo>=</mo><mo stretchy=false>{</mo><msub><mi>o</mi><mn>1</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msub><mi>o</mi><mi>n</mi></msub><mo stretchy=false>}</mo><mi mathvariant=normal>.</mi></mrow><annotation encoding=application/x-tex>o_i = \mathrm{softmax}\!\left(\frac{(P W_Q)(e_i W_K)^\top}{\sqrt{d}}\right) e_i W_V,\quad O_{VE}=\{o_1,\dots,o_n\}.</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal">o</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.4761em;vertical-align:-0.95em></span><span class=mord><span class="mord mathrm">softmax</span></span><span class=mspace style=margin-right:-0.1667em></span><span class=mspace style=margin-right:0.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0em><span class="delimsizing size3">(</span></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.5261em><span style=top:-2.1778em><span class=pstrut style=height:3em></span><span class=mord><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.9322em><span class=svg-align style=top:-3em><span class=pstrut style=height:3em></span><span class=mord style=padding-left:0.833em><span class="mord mathnormal">d</span></span></span><span style=top:-2.8922em><span class=pstrut style=height:3em></span><span class=hide-tail style=min-width:0.853em;height:1.08em><svg xmlns=http://www.w3.org/2000/svg width=400em height=1.08em viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.1078em><span></span></span></span></span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>W</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2861em><span></span></span></span></span></span></span><span class=mclose>)</span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">e</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>W</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.07153em>K</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose><span class=mclose>)</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8491em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.93em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style=top:0em><span class="delimsizing size3">)</span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">e</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord><span class="mord mathnormal" style=margin-right:0.13889em>W</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.1389em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.22222em>V</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:1em></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02778em>O</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.0278em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.22222em>V</span><span class="mord mathnormal mtight" style=margin-right:0.05764em>E</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>{</span><span class=mord><span class="mord mathnormal">o</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3011em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:0.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">o</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.1514em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mclose>}</span><span class=mord>.</span></span></span></span></span>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=multihead-sampler-ms>Multihead Sampler (MS)<a href=#multihead-sampler-ms class=hash-link aria-label="Multihead Sampler (MS)에 대한 직접 링크" title="Multihead Sampler (MS)에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Learns <strong>view weights</strong> for fusion.</li>
<li class=""><strong>Decomposer (2-layer MLP)</strong> maps each view’s <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>[</mo><mi>C</mi><mi>L</mi><mi>S</mi><mo stretchy=false>]</mo></mrow><annotation encoding=application/x-tex>[CLS]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mopen>[</span><span class="mord mathnormal" style=margin-right:0.07153em>C</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style=margin-right:0.05764em>S</span><span class=mclose>]</span></span></span></span> to <strong><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>m</mi><mo>=</mo><mn>4</mn></mrow><annotation encoding=application/x-tex>m=4</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal">m</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>4</span></span></span></span></strong> tokens <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>{</mo><msubsup><mi>e</mi><mi>i</mi><mn>1</mn></msubsup><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msubsup><mi>e</mi><mi>i</mi><mi>m</mi></msubsup><mo stretchy=false>}</mo></mrow><annotation encoding=application/x-tex>\{e_i^{1},\dots,e_i^{m}\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0728em;vertical-align:-0.2587em></span><span class=mopen>{</span><span class=mord><span class="mord mathnormal">e</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8141em><span style=top:-2.4413em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2587em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:0.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">e</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.6644em><span style=top:-2.4413em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.2587em><span></span></span></span></span></span></span><span class=mclose>}</span></span></span></span>.</li>
<li class="">For each token/head <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>j</mi></mrow><annotation encoding=application/x-tex>j</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.854em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.05724em>j</span></span></span></span>: compute attention scores vs. <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>P</mi></mrow><annotation encoding=application/x-tex>P</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span></span></span></span> → mean over prompt tokens → <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msup><mrow><mi mathvariant=normal>w</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>g</mi><mi mathvariant=normal>h</mi><mi mathvariant=normal>t</mi><mi mathvariant=normal>s</mi></mrow><mi>j</mi></msup><mo>∈</mo><msup><mi mathvariant=double-struck>R</mi><mi>n</mi></msup></mrow><annotation encoding=application/x-tex>\mathrm{weights}^j \in \mathbb{R}^n</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.1034em;vertical-align:-0.1944em></span><span class=mord><span class=mord><span class="mord mathrm">weights</span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.909em><span style=top:-3.1473em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6889em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.6644em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span>.</li>
<li class="">Average across heads:<!-- -->
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><msub><mi>w</mi><mrow><mi>M</mi><mi>S</mi></mrow></msub><mo>=</mo><mstyle displaystyle=false scriptlevel=0><mfrac><mn>1</mn><mi>m</mi></mfrac></mstyle><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><msup><mrow><mi mathvariant=normal>w</mi><mi mathvariant=normal>e</mi><mi mathvariant=normal>i</mi><mi mathvariant=normal>g</mi><mi mathvariant=normal>h</mi><mi mathvariant=normal>t</mi><mi mathvariant=normal>s</mi></mrow><mi>j</mi></msup><mo>∈</mo><msup><mi mathvariant=double-struck>R</mi><mi>n</mi></msup><mi mathvariant=normal>.</mi></mrow><annotation encoding=application/x-tex>w_{MS} = \tfrac{1}{m}\sum_{j=1}^{m}\mathrm{weights}^j \in \mathbb{R}^n.</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.5806em;vertical-align:-0.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3283em><span style=top:-2.55em;margin-left:-0.0269em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05764em>MS</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:3.0652em;vertical-align:-1.4138em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.8451em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.394em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.345em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:0.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.6514em><span style=top:-1.8723em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.4138em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class=mord><span class="mord mathrm">weights</span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.909em><span style=top:-3.1473em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.05724em>j</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.7144em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.7144em><span style=top:-3.113em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span><span class=mord>.</span></span></span></span></span>
</li>
</ul>
<p><img decoding=async loading=lazy alt=MS src=/assets/images/vlm-MS-9377813c0cacbbe34ababda969307034.png width=1308 height=866 class=img_ev3q /></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=map-multiview-attributes-perceiver>MAP (Multiview Attributes Perceiver)<a href=#map-multiview-attributes-perceiver class=hash-link aria-label="MAP (Multiview Attributes Perceiver)에 대한 직접 링크" title="MAP (Multiview Attributes Perceiver)에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class=""><strong>Order-invariant weighted fusion</strong>:<!-- -->
<span class=katex-display><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML display=block><semantics><mrow><mtext>Output</mtext><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>w</mi><mi>i</mi></msub><mtext> </mtext><msub><mi>o</mi><mi>i</mi></msub><mi mathvariant=normal>.</mi></mrow><annotation encoding=application/x-tex>\text{Output}=\sum_{i=1}^{n} w_i\,o_i.</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8778em;vertical-align:-0.1944em></span><span class="mord text"><span class=mord>Output</span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:2.9291em;vertical-align:-1.2777em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.6514em><span style=top:-1.8723em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0em><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2777em><span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:0.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:-0.0269em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:0.1667em></span><span class=mord><span class="mord mathnormal">o</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:0.3117em><span style=top:-2.55em;margin-left:0em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.15em><span></span></span></span></span></span></span><span class=mord>.</span></span></span></span></span>
</li>
<li class="">Properties: supports <strong>any number of views</strong>; <strong>permutation-invariant</strong> to input order.</li>
<li class="">By learning weights for each view, MAP highlights informative perspectives and suppresses less useful ones, ensuring consistent predictions even when the view order changes. This directly addresses the input-order sensitivity observed in baselines such as OpenFlamingo.</li>
</ul>
<p><img decoding=async loading=lazy alt=MAP src=/assets/images/vlm-MAP-d20f08f8971017b5de5936f013867d6b.png width=1248 height=732 class=img_ev3q /></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=benchmarks>Benchmarks<a href=#benchmarks class=hash-link aria-label="Benchmarks에 대한 직접 링크" title="Benchmarks에 대한 직접 링크" translate=no>​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=baselines--input-modes>Baselines & Input Modes<a href=#baselines--input-modes class=hash-link aria-label="Baselines & Input Modes에 대한 직접 링크" title="Baselines & Input Modes에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Baselines: <strong>BLIP3</strong>, <strong>OpenFlamingo (4 variants)</strong>, <strong>OPERA</strong>, <strong>Idefics2</strong>, <strong>LLaVA-UHD</strong>.</li>
<li class="">Two input modes:<!-- -->
<ol>
<li class=""><strong>Original image only</strong>.</li>
<li class=""><strong>Original + 8 generated views</strong>.<!-- -->
<ul>
<li class="">Models that accept only one image use <strong>9in1</strong> tiling (nine images stitched into one).</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=main-results>Main Results<a href=#main-results class=hash-link aria-label="Main Results에 대한 직접 링크" title="Main Results에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class=""><strong>MIAVLM</strong>:<!-- -->
<ul>
<li class=""><strong>HoOA metric:</strong> <strong>0.775 / 0.787</strong> (modes 1 / 2)</li>
<li class=""><strong>Positive accuracy:</strong> 0.752 / 0.762</li>
<li class=""><strong>Negative accuracy:</strong> 0.797 / 0.812</li>
<li class=""><strong>Inference time:</strong> <strong>0.071 / 0.105 s</strong> (fastest)</li>
</ul>
</li>
<li class=""><strong>9in1</strong> tiling <strong>did not improve</strong> results (likely harder to interpret).</li>
<li class=""><strong>Nine separate multiview images</strong> generally <strong>improved</strong> performance.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=ablations>Ablations<a href=#ablations class=hash-link aria-label="Ablations에 대한 직접 링크" title="Ablations에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class=""><strong>Negative instructions:</strong> boost <strong>negative-question</strong> accuracy but slightly reduce <strong>positive-question</strong> accuracy; overall HoOA <strong>increases</strong> (approx. <strong>0.665 → 0.787</strong>).</li>
<li class=""><strong>Input-order sensitivity:</strong>
<ul>
<li class="">MIAVLM is <strong>order-invariant</strong></li>
<li class="">OpenFlamingos accuracy varies when shuffling view order.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=limitations--notes>Limitations & Notes<a href=#limitations--notes class=hash-link aria-label="Limitations & Notes에 대한 직접 링크" title="Limitations & Notes에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Trade-off from negative instructions (negatives ↑, positives ↓).</li>
<li class="">Effectiveness depends on the quality of <strong>generated views</strong>.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=insights>Insights<a href=#insights class=hash-link aria-label="Insights에 대한 직접 링크" title="Insights에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">This approach seems especially suitable for perception, where multiple scene views may arrive in arbitrary order, ensuring consistent attribute recognition.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=ref>Ref<a href=#ref class=hash-link aria-label="Ref에 대한 직접 링크" title="Ref에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Tan, Z., Li, Y., Meng, S., Yuan, X., Li, W., Mo, T., Wang, B., & Chu, X. (2025, 6–11 April 2025). Mitigating Hallucinations on Object Attributes using Multiview Images and Negative Instructions. ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).</li>
</ul></div><footer class="row docusaurus-mt-lg"><div class=col><b>태그:</b><ul class="tags_jXut padding--none margin-left--sm"><li class=tag_QGVx><a rel=tag title="Vision-Language Models" class="tag_zVej tagRegular_sFm0" href=/tags/vlm/>vlm</a></ul></div></footer></article><article class=margin-bottom--xl><header><h2 class=title_f1Hy><a href=/2025/08/18/fundamentals-of-software-development-004/>FSD +004</a></h2><div class="container_mt6G margin-vert--md"><time datetime=2025-08-18T00:17:57.360Z>2025년 8월 18일</time> · <!-- -->약 1분</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class=avatar__photo-link href=/authors/me/><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/11773683?v=4" alt="Eunkwang Shin"/></a><div class="avatar__intro authorDetails_lV9A"><div class=avatar__name><a href=/authors/me/><span class=authorName_yefp translate=no>Eunkwang Shin</span></a></div><small class=authorTitle_nd0D title=Owner>Owner</small><div class=authorSocials_rSDt><a href=https://www.linkedin.com/in/gracefullight/ target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=LinkedIn><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em preserveAspectRatio=xMidYMid viewBox="0 0 256 256" style=--dark:#0a66c2;--light:#ffffffe6 class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"/></svg></a><a href=https://github.com/gracefullight target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=GitHub><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em viewBox="0 0 256 250" preserveAspectRatio=xMidYMid style=--dark:#000;--light:#fff class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"/></svg></a><a href=mailto:gracefullight.dev@gmail.com target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=Email><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 24 24" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 class=authorSocialIcon_XYv3><path stroke=none d="M0 0h24v24H0z"/><path d="M7.2 12a4.8 4.8 0 1 0 9.6 0 4.8 4.8 0 1 0-9.6 0"/><path d="M16.8 12v1.8a3 3 0 0 0 6 0V12a10.8 10.8 0 1 0-6.6 9.936"/></svg></a></div></div></div></div></div></header><div class=markdown><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=match>match<a href=#match class=hash-link aria-label="match에 대한 직접 링크" title="match에 대한 직접 링크" translate=no>​</a></h2>
<div class="language-py codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-py codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token keyword" style=color:#00009f>match</span><span class="token plain"> term</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">  </span><span class="token keyword" style=color:#00009f>case</span><span class="token plain"> pattern</span><span class="token operator" style=color:#393A34>-</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">    action</span><span class="token operator" style=color:#393A34>-</span><span class="token number" style=color:#36acaa>1</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">  </span><span class="token keyword" style=color:#00009f>case</span><span class="token plain"> pattern</span><span class="token operator" style=color:#393A34>-</span><span class="token number" style=color:#36acaa>2</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">    action</span><span class="token operator" style=color:#393A34>-</span><span class="token number" style=color:#36acaa>2</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">  </span><span class="token keyword" style=color:#00009f>case</span><span class="token plain"> pattern</span><span class="token operator" style=color:#393A34>-</span><span class="token number" style=color:#36acaa>3</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">    action</span><span class="token operator" style=color:#393A34>-</span><span class="token number" style=color:#36acaa>3</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">  </span><span class="token comment" style=color:#999988;font-style:italic># the underscore _ case executes the default code</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">  </span><span class="token keyword" style=color:#00009f>case</span><span class="token plain"> </span><span class="token keyword" style=color:#00009f>_</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">    action</span><span class="token operator" style=color:#393A34>-</span><span class="token plain">default</span><br/></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=repetition-statements>Repetition Statements<a href=#repetition-statements class=hash-link aria-label="Repetition Statements에 대한 직접 링크" title="Repetition Statements에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">The count-controlled repetition: a fixed number of times.</li>
<li class="">The sentinel-controlled repetition: a designated value that ends the loop.</li>
<li class="">The infinite repetition: continues until externally stopped.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=the-for-loop>The For Loop<a href=#the-for-loop class=hash-link aria-label="The For Loop에 대한 직접 링크" title="The For Loop에 대한 직접 링크" translate=no>​</a></h3>
<div class="language-py codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-py codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token keyword" style=color:#00009f>for</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>&lt;</span><span class="token plain">value</span><span class="token operator" style=color:#393A34>></span><span class="token plain"> </span><span class="token keyword" style=color:#00009f>in</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>&lt;</span><span class="token builtin">range</span><span class="token plain"> of values</span><span class="token operator" style=color:#393A34>></span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">  </span><span class="token operator" style=color:#393A34>&lt;</span><span class="token plain">code</span><span class="token operator" style=color:#393A34>></span><br/></span></code></pre></div></div>
<div class="language-py codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-py codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token builtin">sum</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>0</span><span class="token punctuation" style=color:#393A34>;</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># [1, 2, ..., 19]</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token comment" style=color:#999988;font-style:italic># adds values from 1 to 19 to sum</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>for</span><span class="token plain"> e </span><span class="token keyword" style=color:#00009f>in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style=color:#393A34>(</span><span class="token number" style=color:#36acaa>1</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>20</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">  </span><span class="token builtin">sum</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>+=</span><span class="token plain"> e</span><br/></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token string-interpolation string" style=color:#e3116c>f"The sum is: </span><span class="token string-interpolation interpolation punctuation" style=color:#393A34>{</span><span class="token string-interpolation interpolation builtin">sum</span><span class="token string-interpolation interpolation punctuation" style=color:#393A34>}</span><span class="token string-interpolation string" style=color:#e3116c>"</span><span class="token punctuation" style=color:#393A34>)</span><br/></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=loop-and-a-half>Loop-And-A-Half<a href=#loop-and-a-half class=hash-link aria-label="Loop-And-A-Half에 대한 직접 링크" title="Loop-And-A-Half에 대한 직접 링크" translate=no>​</a></h3>
<div class="language-py codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-py codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">n </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>5</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token builtin">sum</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>0</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>while</span><span class="token plain"> n </span><span class="token operator" style=color:#393A34>&lt;</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>10</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">  </span><span class="token builtin">sum</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>+=</span><span class="token plain"> n</span><br/></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">  </span><span class="token keyword" style=color:#00009f>if</span><span class="token plain"> </span><span class="token builtin">sum</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>></span><span class="token plain"> </span><span class="token number" style=color:#36acaa>100</span><span class="token punctuation" style=color:#393A34>:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token keyword" style=color:#00009f>break</span><br/></span></code></pre></div></div></div><footer class="row docusaurus-mt-lg"><div class=col><b>태그:</b><ul class="tags_jXut padding--none margin-left--sm"><li class=tag_QGVx><a rel=tag class="tag_zVej tagRegular_sFm0" href=/tags/fsd/>fsd</a></ul></div></footer></article><article class=margin-bottom--xl><header><h2 class=title_f1Hy><a href=/2025/08/17/zotero-initial-setup/>Zotero 초기 세팅</a></h2><div class="container_mt6G margin-vert--md"><time datetime=2025-08-17T03:43:37.760Z>2025년 8월 17일</time> · <!-- -->약 1분</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class=avatar__photo-link href=/authors/me/><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/11773683?v=4" alt="Eunkwang Shin"/></a><div class="avatar__intro authorDetails_lV9A"><div class=avatar__name><a href=/authors/me/><span class=authorName_yefp translate=no>Eunkwang Shin</span></a></div><small class=authorTitle_nd0D title=Owner>Owner</small><div class=authorSocials_rSDt><a href=https://www.linkedin.com/in/gracefullight/ target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=LinkedIn><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em preserveAspectRatio=xMidYMid viewBox="0 0 256 256" style=--dark:#0a66c2;--light:#ffffffe6 class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"/></svg></a><a href=https://github.com/gracefullight target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=GitHub><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em viewBox="0 0 256 250" preserveAspectRatio=xMidYMid style=--dark:#000;--light:#fff class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"/></svg></a><a href=mailto:gracefullight.dev@gmail.com target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=Email><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 24 24" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 class=authorSocialIcon_XYv3><path stroke=none d="M0 0h24v24H0z"/><path d="M7.2 12a4.8 4.8 0 1 0 9.6 0 4.8 4.8 0 1 0-9.6 0"/><path d="M16.8 12v1.8a3 3 0 0 0 6 0V12a10.8 10.8 0 1 0-6.6 9.936"/></svg></a></div></div></div></div></div></header><div class=markdown><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=동기화-설정>동기화 설정<a href=#동기화-설정 class=hash-link aria-label="동기화 설정에 대한 직접 링크" title="동기화 설정에 대한 직접 링크" translate=no>​</a></h2>
<blockquote>
<p>Settings - Sync - Data Syncing</p>
</blockquote>
<ul>
<li class="">로그인하고 자동 동기화 설정</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=브라우저-익스텐션-다운로드>브라우저 익스텐션 다운로드<a href=#브라우저-익스텐션-다운로드 class=hash-link aria-label="브라우저 익스텐션 다운로드에 대한 직접 링크" title="브라우저 익스텐션 다운로드에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class=""><a href=https://chromewebstore.google.com/detail/zotero-connector/ekhagklcjbdpajgpjgmbionohlpdbjgc target=_blank rel="noopener noreferrer" class="">Zotero Connector</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=citation-설정>Citation 설정<a href=#citation-설정 class=hash-link aria-label="Citation 설정에 대한 직접 링크" title="Citation 설정에 대한 직접 링크" translate=no>​</a></h2>
<blockquote>
<p>Settings - Cite - APA 7th</p>
</blockquote>
<ul>
<li class="">등록되어있는지 확인</li>
</ul>
<blockquote>
<p>Export - Item Format - APA 7th</p>
</blockquote>
<ul>
<li class="">포맷 설정</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=ms-word-plugin-설치>MS Word Plugin 설치<a href=#ms-word-plugin-설치 class=hash-link aria-label="MS Word Plugin 설치에 대한 직접 링크" title="MS Word Plugin 설치에 대한 직접 링크" translate=no>​</a></h3>
<blockquote>
<p>Settings - Cite - Word Processors</p>
</blockquote>
<ul>
<li class="">Microsoft Word 섹션의 Install/Reinstall Microsoft Word Add-in 클릭</li>
<li class="">워드 재시작</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=플러그인-설치>플러그인 설치<a href=#플러그인-설치 class=hash-link aria-label="플러그인 설치에 대한 직접 링크" title="플러그인 설치에 대한 직접 링크" translate=no>​</a></h2>
<blockquote>
<p>Tools - Plugins</p>
</blockquote>
<ul>
<li class="">다운로드 받은 플러그인 드래그 앤 드랍</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=vscode-플러그인>VSCode 플러그인<a href=#vscode-플러그인 class=hash-link aria-label="VSCode 플러그인에 대한 직접 링크" title="VSCode 플러그인에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">아직 못 찾음</li>
</ul></div><footer class="row docusaurus-mt-lg"><div class=col><b>태그:</b><ul class="tags_jXut padding--none margin-left--sm"><li class=tag_QGVx><a rel=tag class="tag_zVej tagRegular_sFm0" href=/tags/zotero/>zotero</a></ul></div></footer></article><article class=margin-bottom--xl><header><h2 class=title_f1Hy><a href=/2025/08/17/trustworthiness-in-vision-language-models-review/>Trustworthiness in Vision-Language Models Review</a></h2><div class="container_mt6G margin-vert--md"><time datetime=2025-08-17T00:02:41.350Z>2025년 8월 17일</time> · <!-- -->약 6분</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class=avatar__photo-link href=/authors/me/><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/11773683?v=4" alt="Eunkwang Shin"/></a><div class="avatar__intro authorDetails_lV9A"><div class=avatar__name><a href=/authors/me/><span class=authorName_yefp translate=no>Eunkwang Shin</span></a></div><small class=authorTitle_nd0D title=Owner>Owner</small><div class=authorSocials_rSDt><a href=https://www.linkedin.com/in/gracefullight/ target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=LinkedIn><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em preserveAspectRatio=xMidYMid viewBox="0 0 256 256" style=--dark:#0a66c2;--light:#ffffffe6 class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"/></svg></a><a href=https://github.com/gracefullight target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=GitHub><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em viewBox="0 0 256 250" preserveAspectRatio=xMidYMid style=--dark:#000;--light:#fff class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"/></svg></a><a href=mailto:gracefullight.dev@gmail.com target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=Email><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 24 24" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 class=authorSocialIcon_XYv3><path stroke=none d="M0 0h24v24H0z"/><path d="M7.2 12a4.8 4.8 0 1 0 9.6 0 4.8 4.8 0 1 0-9.6 0"/><path d="M16.8 12v1.8a3 3 0 0 0 6 0V12a10.8 10.8 0 1 0-6.6 9.936"/></svg></a></div></div></div></div></div></header><div class=markdown><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=overview>Overview<a href=#overview class=hash-link aria-label="Overview에 대한 직접 링크" title="Overview에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Mitigates exposure of private data, produces harmful outputs, or is vulnerable to attacks.</li>
<li class="">SOTA models: LLaVA, Flamingo, GPT-4</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=privacy>Privacy<a href=#privacy class=hash-link aria-label="Privacy에 대한 직접 링크" title="Privacy에 대한 직접 링크" translate=no>​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=privacy-issues>Privacy Issues<a href=#privacy-issues class=hash-link aria-label="Privacy Issues에 대한 직접 링크" title="Privacy Issues에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">risk escalates significantly with relevant images as optimizing in the pixel domain is easier than in text</li>
<li class="">can unintentionally memorize sensitive data, leading to leaks without knowledge of the model’s specifics</li>
<li class="">Overfitting may also cause retention of sensitive attributes during inference</li>
<li class="">gradient-based and backdoor attacks further jeopardize VLM privacy with open-source data</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=privacy-mitigation-methods>Privacy Mitigation Methods<a href=#privacy-mitigation-methods class=hash-link aria-label="Privacy Mitigation Methods에 대한 직접 링크" title="Privacy Mitigation Methods에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">New metrics have been created to assess a model’s ability to reproduce training instances and facilitate cross-model comparisons</li>
<li class="">models utilizing multiple modalities provide better privacy</li>
<li class="">safety modules can be integrated to boost resilience against violations</li>
<li class="">adversarial training can enhance privacy but risks reducing accuracy</li>
<li class="">New architecture: differentially private CLIP model</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=privacy-future-research-directions>Privacy Future Research Directions<a href=#privacy-future-research-directions class=hash-link aria-label="Privacy Future Research Directions에 대한 직접 링크" title="Privacy Future Research Directions에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Cryptography-based Privacy Preservation<!-- -->
<ul>
<li class="">Secure multi-party computation (SMPC): divides secret information into shares among multiple parties, ensuring that individual shares reveal nothing unless combined</li>
<li class="">Homomorphic encryption (HE): allows computations on encrypted data without decryption, and has also been utilized for privacy preservation in transformers</li>
</ul>
</li>
<li class="">Federated Learning<!-- -->
<ul>
<li class="">enhances privacy in vision-language models (VLMs) by localizing model training, which protects training data from leakage.</li>
<li class="">challenges such as communication overhead among devices and statistical heterogeneity from diverse data distributions</li>
</ul>
</li>
<li class="">Data Manipulation and Finetunning<!-- -->
<ul>
<li class="">Data pseudonymization: substitutes sensitive information with synthetic alternatives.</li>
<li class="">Data Sanitization: removes duplicates to reduce memorization and privacy risks.</li>
<li class="">knowledge sanitization-fine-tuning: provide safe responses when leakage risks arise.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=fairness-and-bias>Fairness and Bias<a href=#fairness-and-bias class=hash-link aria-label="Fairness and Bias에 대한 직접 링크" title="Fairness and Bias에 대한 직접 링크" translate=no>​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=fairness-and-bias-issues>Fairness and Bias Issues<a href=#fairness-and-bias-issues class=hash-link aria-label="Fairness and Bias Issues에 대한 직접 링크" title="Fairness and Bias Issues에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Bias from training data<!-- -->
<ul>
<li class="">disproportionately features men and lighter-skinned individuals</li>
<li class="">outdated vocabulary and imbalanced representation</li>
<li class="">clinical models may favor certain patient groups based on gender, language, etc.</li>
</ul>
</li>
<li class="">Bias from Model<!-- -->
<ul>
<li class="">Gender biases</li>
<li class="">misclassification of race-related elements and biased outputs</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=fairness-and-bias-mitigation-methods>Fairness and Bias Mitigation Methods<a href=#fairness-and-bias-mitigation-methods class=hash-link aria-label="Fairness and Bias Mitigation Methods에 대한 직접 링크" title="Fairness and Bias Mitigation Methods에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">New Datasets and Benchmarks<!-- -->
<ul>
<li class="">Harvard-FairVLMed, PATA, and BOLD enhance evaluations but often lack the scale of established benchmarks.</li>
<li class="">create synthetic datasets to improve fairness assessments<!-- -->
<ul>
<li class="">gender-balanced dataset generated with DALL-E-3 and another consisting of gender-swapped images</li>
<li class="">counterfactual image-text pairs that highlight biases in datasets like COCO Captions</li>
</ul>
</li>
<li class="">new metrics<!-- -->
<ul>
<li class="">gender polarity</li>
<li class="">bias distance in embeddings</li>
</ul>
</li>
<li class="">human evaluation</li>
</ul>
</li>
<li class="">De-biasing<!-- -->
<ul>
<li class="">adjust model instructions and architectures for improved fairness</li>
<li class="">detecting biased prompts in pre-trained models</li>
<li class="">Post-hoc Bias Mitigation (PBM) effectively reduce bias in image retrieval</li>
<li class="">Re-sampling underperforming clusters can enhance fairness</li>
<li class="">modification of facial features also mitigate biases</li>
<li class="">self-debiasing reduces biased text generation, especially when paired with other methods</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=fairness-future-research-directions>Fairness Future Research Directions<a href=#fairness-future-research-directions class=hash-link aria-label="Fairness Future Research Directions에 대한 직접 링크" title="Fairness Future Research Directions에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Optimized De-biasing<!-- -->
<ul>
<li class="">Additive residual learning: for fairer image representations.</li>
<li class="">Calibration loss: retain semantically similar embeddings.</li>
<li class="">Counterfactual inference framework: help models learn correct responses through cause and effect.</li>
<li class="">Adversarial classifiers: predict image attributes from visual-textual similarities can be combined with instruction tuning to reduce bias.</li>
</ul>
</li>
<li class="">Disentangled Representation Learning (DRL): simplifies complex data by breaking it in to independent feature groups, improving model predictions.<!-- -->
<ul>
<li class="">Traditional DRL<!-- -->
<ul>
<li class="">Variational autoencoders (VAEs) for feature encoding based on impact</li>
<li class="">Generative adversarial networks (GANs) for separation.</li>
</ul>
</li>
<li class="">Attention in text encoders can be adjusted for fairer outputs.</li>
<li class="">challenges: varying definitions of "disentanglement", ensuring fairness.</li>
</ul>
</li>
<li class="">Human-in-the-Loop (HITL): integrating human intervention into their training to improve precision and fairness<!-- -->
<ul>
<li class="">active learning</li>
<li class="">reinforcement learning with human feedback</li>
<li class="">explainable AI</li>
<li class="">challenges: human bias, finance, and ethical and legal issues persist</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=robustness>Robustness<a href=#robustness class=hash-link aria-label="Robustness에 대한 직접 링크" title="Robustness에 대한 직접 링크" translate=no>​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=robustness-issues>Robustness Issues<a href=#robustness-issues class=hash-link aria-label="Robustness Issues에 대한 직접 링크" title="Robustness Issues에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Out-of-Distribution (OOD) Robustness<!-- -->
<ul>
<li class="">ChatGPT excels in adversarial tasks but struggles with OOD robustness and informal medical responses</li>
<li class="">MLLMs often fail to generalize beyond training domains due to mapping issues</li>
<li class="">vision-language models face difficulties with open-domain concepts, especially when overfitting during fine-tuning</li>
<li class="">Large pre-trained image classifiers show initial robustness, which diminishes over time</li>
<li class="">Current visual question answering (VQA) models are limited to specific benchmarks, hindering generalization to OOD datasets</li>
<li class="">fine-tuning may impair model calibration in OOD contexts.</li>
</ul>
</li>
<li class="">Adversarial Attack Robustness<!-- -->
<ul>
<li class="">Studies indicate that open-sourced VLMs show performance gaps in red teaming tasks, highlighting the need for improved safety and security.</li>
<li class="">misalignment between language and vision modalities creates a "modality gap", complicating adversarial vulnerability.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=robustness-mitigation-methods>Robustness Mitigation Methods<a href=#robustness-mitigation-methods class=hash-link aria-label="Robustness Mitigation Methods에 대한 직접 링크" title="Robustness Mitigation Methods에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Improving Out-of-Distribution Robustness<!-- -->
<ul>
<li class="">enhance OOD detection and generalization. A simple maximum logit detector has been shown to outperform complex methods for anomaly segmentation</li>
<li class="">In-context learning (ICL) can also improve multimodal generalization</li>
<li class="">A fine-tuned CLIP excels in unsupervised OOD detection</li>
<li class="">The OGEN method synthesizes OOD features</li>
<li class="">Maximum Concept Matching aligns visual and textual features, and anchor-based finetuning leads to better domain shifts</li>
</ul>
</li>
<li class="">Defense Against Adversarial Attacks<!-- -->
<ul>
<li class="">VILLA is a two-stage framework for adversarial training of VLMs, featuring task-agnostic <strong>adversarial pre-training</strong> and <strong>task-specific finetuning</strong>
<ul>
<li class="">conducts adversarial training in the embedding space rather than on raw image pixels and text tokens, improving the model’s resilience against adversarial examples</li>
<li class="">SOTA performance across various tasks</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=robustness-future-research-directions>Robustness Future Research Directions<a href=#robustness-future-research-directions class=hash-link aria-label="Robustness Future Research Directions에 대한 직접 링크" title="Robustness Future Research Directions에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Data Augmentation<!-- -->
<ul>
<li class="">MixGen: a data augmentation method that generates new image-text pairs by interpolating images and concatenating text to preserve semantics.</li>
<li class="">creating synthetic images involves extracting text prompts via an image captioning model for use in text-to-image diffusion, then mixing these with real datasets.</li>
<li class="">bimodal augmentation (BiAug): decouples objects and attributes to synthesize vision-language examples and hard negatives, using LLMs and an object detector to generate detailed descriptions and inpaint corresponding images.</li>
</ul>
</li>
<li class="">Improved Cross-Modal Alignment<!-- -->
<ul>
<li class="">Sharing learnable parameters</li>
<li class="">Applying bidirectional constraints</li>
<li class="">Adjusting cross-modal projections</li>
</ul>
</li>
<li class="">challenges: addressing the modality gap, which impacts robustness to OOD data and adversarial examples</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=safety>Safety<a href=#safety class=hash-link aria-label="Safety에 대한 직접 링크" title="Safety에 대한 직접 링크" translate=no>​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=safety-issues>Safety Issues<a href=#safety-issues class=hash-link aria-label="Safety Issues에 대한 직접 링크" title="Safety Issues에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Toxicity<!-- -->
<ul>
<li class="">LAION-400M: contains problematic content, including explicit materials and harmful stereotypes</li>
<li class="">Advanced models like GeminiProVision and GPT-4V show inherent biases</li>
<li class="">Assigning personas to ChatGPT can increase toxicity and reinforce harmful stereotypes</li>
</ul>
</li>
<li class="">Jailbreaking Risk<!-- -->
<ul>
<li class="">Perturbation can be performed effectively, while FigStep converts harmful content into images with an 82.5% attack rate across multiple VLMs</li>
<li class="">replaces captions with malicious prompts, enabling jailbreaks.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=safety-mitigation-methods>Safety Mitigation Methods<a href=#safety-mitigation-methods class=hash-link aria-label="Safety Mitigation Methods에 대한 직접 링크" title="Safety Mitigation Methods에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class=""><strong>Safety Fine-Tuning</strong>
<ul>
<li class="">VLGuard</li>
<li class="">fine-tuned on synthetic data, reducing sensitivity to NSFW inputs and enhancing performance in cross-modal tasks</li>
</ul>
</li>
<li class="">Other approach<!-- -->
<ul>
<li class="">Reinforce-Detoxify: uses reinforcement learning to mitigate toxicity and bias in transformer models</li>
<li class="">simple mitigations improve automatic scores, these methods risk over-filtering marginalized texts and create discrepancies between automatic and human judgments</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=safety-future-research-directions>Safety Future Research Directions<a href=#safety-future-research-directions class=hash-link aria-label="Safety Future Research Directions에 대한 직접 링크" title="Safety Future Research Directions에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Context Awareness<!-- -->
<ul>
<li class="">integrating Chain-of-Thought for improved reasoning can enhance CAER tasks with Large VLMs.</li>
<li class="">Dual-Aligned Prompt Tuning: combines explicit context from pre-trained LLMs with implicit modeling to create more context-aware prompts</li>
<li class="">Visual In-Context Learning: optimizes image retrieval and summarization to enhance task-specific interactions.</li>
</ul>
</li>
<li class="">Automated Red Teaming (ART)<!-- -->
<ul>
<li class="">RTVLM: a dataset that benchmarks VLMs across faithfulness, privacy, safety, and fairness</li>
<li class="">Arondight: automates multi-modal jailbreak attacks using reinforcement learning and uncovers significant security vulnerabilities</li>
<li class="">GPT-4 and GPT-4V are more robust against jailbreaks than open-source models</li>
<li class="">limited transferability of visual jailbreak methods compared to textual ones</li>
<li class="">connects unsafe outputs to prompts, improving the detection of vulnerabilities in text-to-image models</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=ref>Ref<a href=#ref class=hash-link aria-label="Ref에 대한 직접 링크" title="Ref에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Vu, K., & Lai, P. (2025). Trustworthiness in Vision-Language Models. In J. Kertesz, B. Li, T. Supnithi, & A. Takhom, Computational Data and Social Networks Singapore.</li>
</ul></div><footer class="row docusaurus-mt-lg"><div class=col><b>태그:</b><ul class="tags_jXut padding--none margin-left--sm"><li class=tag_QGVx><a rel=tag title="Vision-Language Models" class="tag_zVej tagRegular_sFm0" href=/tags/vlm/>vlm</a></ul></div></footer></article><article class=margin-bottom--xl><header><h2 class=title_f1Hy><a href=/2025/08/16/vision-language-models-for-vision-tasks-review/>Vision-Language Models for Vision Tasks Review</a></h2><div class="container_mt6G margin-vert--md"><time datetime=2025-08-16T07:40:55.588Z>2025년 8월 16일</time> · <!-- -->약 16분</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class=avatar__photo-link href=/authors/me/><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/11773683?v=4" alt="Eunkwang Shin"/></a><div class="avatar__intro authorDetails_lV9A"><div class=avatar__name><a href=/authors/me/><span class=authorName_yefp translate=no>Eunkwang Shin</span></a></div><small class=authorTitle_nd0D title=Owner>Owner</small><div class=authorSocials_rSDt><a href=https://www.linkedin.com/in/gracefullight/ target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=LinkedIn><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em preserveAspectRatio=xMidYMid viewBox="0 0 256 256" style=--dark:#0a66c2;--light:#ffffffe6 class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"/></svg></a><a href=https://github.com/gracefullight target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=GitHub><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em viewBox="0 0 256 250" preserveAspectRatio=xMidYMid style=--dark:#000;--light:#fff class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"/></svg></a><a href=mailto:gracefullight.dev@gmail.com target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=Email><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 24 24" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 class=authorSocialIcon_XYv3><path stroke=none d="M0 0h24v24H0z"/><path d="M7.2 12a4.8 4.8 0 1 0 9.6 0 4.8 4.8 0 1 0-9.6 0"/><path d="M16.8 12v1.8a3 3 0 0 0 6 0V12a10.8 10.8 0 1 0-6.6 9.936"/></svg></a></div></div></div></div></div></header><div class=markdown><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=overview>Overview<a href=#overview class=hash-link aria-label="Overview에 대한 직접 링크" title="Overview에 대한 직접 링크" translate=no>​</a></h2>
<blockquote>
<p>Most visual recognition studies rely heavily on crowdlabelled data in DNN</p>
</blockquote>
<ul>
<li class="">Background development of visual recognition paradigms</li>
<li class="">Foundations its architecture</li>
<li class="">Datasets in VLM pre-training and evaluations</li>
<li class="">Review and categorization of existing pre-training methods</li>
<li class="">Benchmarking analysis discussion</li>
<li class="">Reach challenges & potential research direction</li>
<li class="">Training hard<!-- -->
<ul>
<li class="">New learning paradigm</li>
</ul>
</li>
<li class="">Vision-Language Model Pre-training and Zero-shot Prediction<!-- -->
<ul>
<li class="">Increasing attention</li>
</ul>
</li>
<li class="">VLMs with transfer learning<!-- -->
<ul>
<li class="">Prompt tuning</li>
<li class="">Visual adaption</li>
</ul>
</li>
<li class="">VLMs with knowledge distillation<!-- -->
<ul>
<li class="">distill knowledge from VLMs to downstream tasks</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=the-development-of-visual-recognition-paradigms>The development of visual recognition paradigms<a href=#the-development-of-visual-recognition-paradigms class=hash-link aria-label="The development of visual recognition paradigms에 대한 직접 링크" title="The development of visual recognition paradigms에 대한 직접 링크" translate=no>​</a></h2>
<!-- -->
<ul>
<li class="">Traditional ML: Hand-crafted features for prediction.</li>
<li class="">Deep Learning: Deep networks (e.g., ResNet) with large-scale labeled data.</li>
<li class="">Supervised Pre-training + Fine-tuning: Learned representations transferred to downstream tasks.</li>
<li class="">Unsupervised / Self-supervised Pre-training + Fine-tuning: Objectives like masked modeling and contrastive learning to learn representations.</li>
<li class="">Vision-Language Models & Zero-shot: Leverage large-scale web data, enabling zero-shot prediction without task-specific fine-tuning.<!-- -->
<ul>
<li class="">Collecting large-scale informative image-text data</li>
<li class="">Designing high-capacity models for effective learning from Bigdata.</li>
<li class="">Designing new pre-training objectives for learning effective VLMs.</li>
</ul>
</li>
</ul>
<p><img decoding=async loading=lazy alt="Illustration of development of VLMs for visual recognition" src=/assets/images/vlm-paradigm-46050660982130f887307cc0442975c0.png width=701 height=347 class=img_ev3q /></p>
<ul>
<li class="">CLIP: Image-text contrastive objective and learns by pulling the paired images and texts close and pushing others faraway in the embedding space.<!-- -->
<ul>
<li class="">enables effective usage of web data and allows zero-shot predictions without task-specific finetuning.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=vlm-overview>VLM Overview<a href=#vlm-overview class=hash-link aria-label="VLM Overview에 대한 직접 링크" title="VLM Overview에 대한 직접 링크" translate=no>​</a></h2>
<p><img decoding=async loading=lazy alt="VLM Overview" src=/assets/images/vlm-overview-2abb2d65aeef690c49e399a7ca3ac86c.png width=1400 height=728 class=img_ev3q /></p>
<ul>
<li class="">Given Image-text pairs.</li>
<li class="">Employs a text encoder and an image encoder to extract image and text features.</li>
<li class="">Learns the vision-language correlation with certain pre-training objectives.</li>
<li class="">GAP: Global Average Pooling, a technique used to reduce the spatial dimensions of feature maps while retaining important information.</li>
<li class="">ViT: Vision Transformer: Transformers for image recognition at scale.</li>
<li class="">CNN Based: VGG, <strong>ResNet</strong>, EfficientNet<!-- -->
<ul>
<li class="">ResNet: Adopts skip connections between convolutional blocks which mitigates gradient vanishing and explosion and enables DNN training.</li>
<li class="">ResNet-D: Replace global average pooling with transformer multi-head attention.</li>
</ul>
</li>
<li class="">Transformer Based: ViT<!-- -->
<ul>
<li class="">Adding a normalization layer before the transformer encoder.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=vlm-pre-training-objectives>VLM pre-training Objectives<a href=#vlm-pre-training-objectives class=hash-link aria-label="VLM pre-training Objectives에 대한 직접 링크" title="VLM pre-training Objectives에 대한 직접 링크" translate=no>​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=contrastive-objectives>Contrastive Objectives<a href=#contrastive-objectives class=hash-link aria-label="Contrastive Objectives에 대한 직접 링크" title="Contrastive Objectives에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Pros<!-- -->
<ul>
<li class="">Enforce positive pairs to have similar embeddings in contrast to negative pairs.</li>
<li class="">Encourages VLMs to learn discriminative vision and language features, where more discriminative features lead to more confident and accurate zero-shot predictions.</li>
</ul>
</li>
<li class="">Cons<!-- -->
<ul>
<li class="">Joint optimizing positive and negative pairs is complicated and challenging.</li>
<li class="">Involves a heuristic temperature hyper-parameter for controlling the feature discriminability.</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=image-contrastive-learning>Image Contrastive Learning<a href=#image-contrastive-learning class=hash-link aria-label="Image Contrastive Learning에 대한 직접 링크" title="Image Contrastive Learning에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class="">Forcing a query image to be close with its positive keys (its data augmentations)</li>
<li class="">Faraway from its negative keys (other images)</li>
<li class=""><strong>Learn discriminative features</strong> in image modality, which often serves as an auxiliary objective for fully exploiting the image data potential.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=image-text-contrastive-learning>Image-Text Contrastive Learning<a href=#image-text-contrastive-learning class=hash-link aria-label="Image-Text Contrastive Learning에 대한 직접 링크" title="Image-Text Contrastive Learning에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class="">Pulling the embeddings of paired images and texts close while pushing others away.</li>
<li class="">Minimizing a symmetrical image-text infoNCE loss</li>
<li class=""><strong>Learn vision-language correlation</strong> by contrasting image-text pairs.<!-- -->
<ul>
<li class="">CLIP: A symmetrical image-text infoNCE loss</li>
<li class="">ALIGN: scales up the VLM pre-training with large-scale (but noisy image-text pair with noise-robust contrastive learning)</li>
<li class="">DeCLIP: Nearest-neighbor supervision to utilize the information from similar pairs, enabling effective pre-training on limited data.</li>
<li class="">OTTER: Optimal transport to pseudo-pair images and texts reducing the required training data.</li>
<li class="">ZeroVL: Limited data resource via debiased data sampling and data augmentation with coin flipping mixup.</li>
<li class="">FILIP: Region-word alignment into contrastive learning, enabling to learn fine-grained vision-language corresponding knowledge.</li>
<li class="">Pyramid-CLIP: Multiple semantic levels and performs both cross-level and peer-level contrastive learning for effective VLM pre-training.</li>
<li class="">LA-CLIP, ALIP: LLM to augment synthetic captions for given images while RA-CLIP retrieves relevant image-text pairs for image-text pair augmentation.</li>
</ul>
</li>
</ul>
<p><img decoding=async loading=lazy alt=CLIP src=/assets/images/vlm-clip-002c83bc065d184a2350741cacc71908.png width=848 height=528 class=img_ev3q /></p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=image-text-label-contrastive-learning>Image-Text-Label Contrastive Learning<a href=#image-text-label-contrastive-learning class=hash-link aria-label="Image-Text-Label Contrastive Learning에 대한 직접 링크" title="Image-Text-Label Contrastive Learning에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class="">Supervised Contrastive Learning into image-text contrastive learning.</li>
<li class=""><strong>Learn discriminative and task-specific features</strong> by exploiting both supervised labels and unsupervised image-text pairs.<!-- -->
<ul>
<li class="">UniCL: pre-training allows learning both discriminative and task-specific (image classification) features simultaneously with around 900M image-text pairs.</li>
</ul>
</li>
</ul>
<p><img decoding=async loading=lazy alt="Image-Text-Label Contrastive Learning" src=/assets/images/vlm-image-text-label-83c01a33a07520e54ac28a0ffbb1ceaa.png width=846 height=558 class=img_ev3q /></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=generative-objectives>Generative Objectives<a href=#generative-objectives class=hash-link aria-label="Generative Objectives에 대한 직접 링크" title="Generative Objectives에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Encouraging VLMs to learn rich vision, language and vision-language contexts for better zero-shot predictions.</li>
<li class="">Generally adopted as additional objectives above other VLM pre-training objectives for learning rich context information.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=masked-image-modelling>Masked Image Modelling<a href=#masked-image-modelling class=hash-link aria-label="Masked Image Modelling에 대한 직접 링크" title="Masked Image Modelling에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class="">Cross-patch correlation by masking and reconstructing images.</li>
<li class=""><strong>Learn image context information by masking and reconstructing images</strong>
<ul>
<li class="">MAE, BeiT: certain patches in an image are masked and the encoder is trained to reconstruct them conditioned on unmasked patches.</li>
</ul>
</li>
</ul>
<p><img decoding=async loading=lazy alt="Masked Image Modelling" src=/assets/images/vlm-masked-image-modelling-0b2757747dbb1e20d94920022ed416e1.png width=936 height=424 class=img_ev3q /></p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=masked-language-modelling>Masked Language Modelling<a href=#masked-language-modelling class=hash-link aria-label="Masked Language Modelling에 대한 직접 링크" title="Masked Language Modelling에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class="">Adopted pre-training objectives in NLP.</li>
<li class="">Randomly masking a certain percentage of input tokens and predicting them. (15% in BERT)</li>
<li class=""><strong>Learn by masking a fraction of tokens</strong> in each input text and training networks to predict the masked tokens.<!-- -->
<ul>
<li class="">FLAVA: masks out 15% text tokens and reconstructs them from the rest tokens for modelling cross-word correlation.</li>
<li class="">FIBER: adopts masked language modelling as one of the VLM pre-training objectives to extract better language features.</li>
</ul>
</li>
</ul>
<p><img decoding=async loading=lazy alt="Masked Language Modelling" src=/assets/images/vlm-masked-language-modelling-4673252375ddfbf207081514c51e2eae.png width=868 height=454 class=img_ev3q /></p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=masked-cross-modal-modelling>Masked Cross-Modal Modelling<a href=#masked-cross-modal-modelling class=hash-link aria-label="Masked Cross-Modal Modelling에 대한 직접 링크" title="Masked Cross-Modal Modelling에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class="">Integrates masked image modelling and masked language modelling.</li>
<li class="">Given an image-text pair, it randomly masks a subset of image patches and a subset of text tokens and then learns to reconstruct them.</li>
<li class=""><strong>Learn by masking a certain percentage of image patches and text tokens</strong> and training VLMs to reconstruct them based on the embeddings of unmasked image patches and text tokens.<!-- -->
<ul>
<li class="">FLAVA: 40% image patches and 15% text tokens as in, and employs a MLP to predict masked patched and tokens, capturing rich vision-language correspondence information.</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=image-to-text-generation>Image-to-Text Generation<a href=#image-to-text-generation class=hash-link aria-label="Image-to-Text Generation에 대한 직접 링크" title="Image-to-Text Generation에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class=""><strong>Generate descriptive texts for a given image</strong> for capturing fine-grained vision-language correlation by training VLMs to predict tokenized texts.<!-- -->
<ul>
<li class="">COCA, NLP, PaLI: train VLMs with the standard encoder-decoder architecture and image captioning objectives.</li>
</ul>
</li>
</ul>
<p><img decoding=async loading=lazy alt="Image to caption" src=/assets/images/vlm-image-to-caption-4348d37878d43e85e49b73006131f2c2.png width=924 height=712 class=img_ev3q /></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=alignment-objectives>Alignment Objectives<a href=#alignment-objectives class=hash-link aria-label="Alignment Objectives에 대한 직접 링크" title="Alignment Objectives에 대한 직접 링크" translate=no>​</a></h3>
<blockquote>
<p>Align image–text pairs in the embedding space.</p>
</blockquote>
<ul>
<li class="">pros<!-- -->
<ul>
<li class="">simple, easy to optimize</li>
<li class="">can be easily extended to model fine-grained vision-language correlation</li>
</ul>
</li>
<li class="">cons<!-- -->
<ul>
<li class="">little correlation information within vision or language modality.</li>
</ul>
</li>
<li class="">adopted as auxiliary losses to other VLM pre-training objectives for enhancing modelling the correlation across vision and language modalities.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=image-text-matching>Image-Text Matching<a href=#image-text-matching class=hash-link aria-label="Image-Text Matching에 대한 직접 링크" title="Image-Text Matching에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class="">models the <strong>overall correlation</strong> between an entire image and an entire sentence. (전역적 상관관계)</li>
<li class="">Image-text matching models global image-text correlation by directly aligning paired images and texts<!-- -->
<ul>
<li class="">FLAVA: matches the given image with its paired text via a classifier and a binary classification loss.</li>
<li class="">FIBER: follows to mine hard negatives with pair-wise similarities for better alignment between image and text.</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=region-word-matching>Region-Word Matching<a href=#region-word-matching class=hash-link aria-label="Region-Word Matching에 대한 직접 링크" title="Region-Word Matching에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class="">captures <strong>fine-grained correlations</strong> between image regions and specific words. (지역적 상관관계)</li>
<li class="">models local fine-grained vision-language correlation by aligning paired image regions and word tokens.</li>
<li class="">benefiting <strong>zero-shot dense predictions</strong> in object detection and semantic segmentation.<!-- -->
<ul>
<li class="">GLIP, FIBER, DetCLIP: replace object classification logits by region-word alignment scores.<!-- -->
<ul>
<li class="">the dot-product similarity between regional visual features and token-wise features.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img decoding=async loading=lazy alt="Region-Word Matching, GLIP" src=/assets/images/vlm-region-word-578b649828e666c5d4d0a9ca7af22e51.png width=942 height=538 class=img_ev3q /></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=vlm-pre-training-frameworks>VLM Pre-Training Frameworks<a href=#vlm-pre-training-frameworks class=hash-link aria-label="VLM Pre-Training Frameworks에 대한 직접 링크" title="VLM Pre-Training Frameworks에 대한 직접 링크" translate=no>​</a></h3>
<p><img decoding=async loading=lazy alt="VLM pre-training frameworks" src=/assets/images/vlm-pretraining-frameworks-39991946607c915ff2a7126f16d59c30.png width=715 height=273 class=img_ev3q /></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=evaluation>Evaluation<a href=#evaluation class=hash-link aria-label="Evaluation에 대한 직접 링크" title="Evaluation에 대한 직접 링크" translate=no>​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=zero-shot-prediction>Zero-shot Prediction<a href=#zero-shot-prediction class=hash-link aria-label="Zero-shot Prediction에 대한 직접 링크" title="Zero-shot Prediction에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Image Classification: classify images into pre-defined categories like "prompt engineering".</li>
<li class="">Semantic Segmentation: by comparing the embeddings of the given image pixels and texts.</li>
<li class="">Object Detection: localize and classify objects in images with the object locating ability learned from auxiliary datasets.</li>
<li class="">Image-Text Retrieval<!-- -->
<ul>
<li class="">Text-to-image retrieval that retrieves images based on texts</li>
<li class="">Image-to-text retrieval that retrieves texts based on images.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=linear-probing>Linear Probing<a href=#linear-probing class=hash-link aria-label="Linear Probing에 대한 직접 링크" title="Linear Probing에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">freezes the pre-trained VLM</li>
<li class="">trains a linear classifier to classify the VLM-encoded embeddings to assess the VLM representations.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=datasets>Datasets<a href=#datasets class=hash-link aria-label="Datasets에 대한 직접 링크" title="Datasets에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">For Pre-training VLMs<!-- -->
<ul>
<li class="">CLIP, 2021, 400M, English</li>
<li class="">ALIGN, 2021, 1.8B, English</li>
<li class="">FILIP, 2021, 300M, English</li>
<li class="">WebLi, 2022, 12B, 129 Languages</li>
</ul>
</li>
<li class="">For VLM Evaluation<!-- -->
<ul>
<li class="">Image Classification<!-- -->
<ul>
<li class="">PSACAL VOC 2007 Classification, 11-point mAP</li>
<li class="">Oxford-IIIT PETS, Mean Per Class</li>
<li class="">EuroSAT, Accuracy</li>
<li class="">Hateful Memes, ROC AUC</li>
<li class="">Country211, Accuracy</li>
</ul>
</li>
<li class="">Image-Text Retrieval<!-- -->
<ul>
<li class="">Flickr30k, Recall</li>
<li class="">COCO Caption, Recall</li>
</ul>
</li>
<li class="">Action Recognition<!-- -->
<ul>
<li class="">UCF101, Accuracy</li>
<li class="">Kinetics700, Mean(top1, top5)</li>
<li class="">RareAct, mWAP, mSAP</li>
</ul>
</li>
<li class="">Object Detection<!-- -->
<ul>
<li class="">COCO 2017 Detection, box mAP</li>
<li class="">LVIS, box mAP</li>
<li class="">ODinW, box mAP</li>
</ul>
</li>
<li class="">Semantic Segmentation<!-- -->
<ul>
<li class="">Cityscapes, Mean IoU</li>
<li class="">ADE20K, Mean IoU</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=vlm-transfer-learning>VLM Transfer learning<a href=#vlm-transfer-learning class=hash-link aria-label="VLM Transfer learning에 대한 직접 링크" title="VLM Transfer learning에 대한 직접 링크" translate=no>​</a></h2>
<blockquote>
<p>which adapts VLMs to fit downstream tasks via prompt tuning, feature adapter.</p>
</blockquote>
<ul>
<li class="">image and text distributions gap: downstream dataset may have task-specific image styles and text formats</li>
<li class="">training objectives gap: VLMs are generally trained with task-agnostic objectives, while downstream tasks often involve task-specific objectives. (coarse or fine-grained classification, region or pixel-level recognition)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=transfer-via-prompt-tuning>Transfer via Prompt Tuning<a href=#transfer-via-prompt-tuning class=hash-link aria-label="Transfer via Prompt Tuning에 대한 직접 링크" title="Transfer via Prompt Tuning에 대한 직접 링크" translate=no>​</a></h3>
<blockquote>
<p>Inspired by the "prompt learning" in NLP</p>
</blockquote>
<ul>
<li class="">pros<!-- -->
<ul>
<li class="">simple, easy-to-implement</li>
<li class="">requires little extra network layer or complex network modifications</li>
<li class="">adapting VLMs in a black-box manner, which has clear advantages in transferring VLMs that involve concerns in intellectual property.</li>
</ul>
</li>
<li class="">cons<!-- -->
<ul>
<li class="">low flexibility by following the manifold (잠재 공간) of the original VLMs in prompting.</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=transfer-with-text-prompt-tuning>Transfer with Text Prompt Tuning<a href=#transfer-with-text-prompt-tuning class=hash-link aria-label="Transfer with Text Prompt Tuning에 대한 직접 링크" title="Transfer with Text Prompt Tuning에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class="">Exploring more effective and efficient learnable text prompts with several labelled downstream samples for each class.<!-- -->
<ul>
<li class=""><strong>supervised and few-shot supervised</strong>
<ul>
<li class="">CoOp: Exploring context optimization to learn context words for a single class name with learnable word vectors.</li>
<li class="">CoCoOp: Exploring conditional context optimization that generates a specific prompt for each image.</li>
<li class="">SubPT: designs subspace prompt tuning to improve the generalization of learned prompts.</li>
<li class="">LASP: regularizes learnable prompts with hand-engineered prompts.</li>
<li class="">VPT: models text prompts with instance-specific distribution with better generalization on downstream tasks.</li>
<li class="">KgCoOp: enhances the generalization of unseen class by mitigating the forgetting of textual knowledge.</li>
<li class="">SoftCPT: fine-tunes VLMs on multiple few-shot tasks simultaneously for benefiting from multi-task learning.</li>
<li class="">PLOT: employs optimal transport to learn multiple prompts to describe the diverse characteristics of a category.</li>
<li class="">DualCoOp, TaI-DP: transport VLMs to multi-label classification tasks.<!-- -->
<ul>
<li class="">DualCoOp: adopts both positive and negative prompts for multi-label classification</li>
<li class="">TaI-DP: double-grained prompt tuning for capturing both coarse-grained and fine-grained embeddings.</li>
</ul>
</li>
<li class="">DenseCLIP: explores language-guided fine-tuning that employs visual features to tune text prompts for dense prediction.</li>
<li class="">ProTeCt: improves the consistency of model predictions for hierarchical classification task.</li>
</ul>
</li>
<li class=""><strong>unsupervised</strong>
<ul>
<li class="">UPL: optimizes learnable prompts with self-training on selected pseudo-labeled samples.</li>
<li class="">TPT: explores test-time prompt tuning to learn adaptive prompts from a single downstream sample.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img decoding=async loading=lazy alt="Text Prompt Tuning" src=/assets/images/vlm-text-prompt-tuning-90bb346d2a9f42bf7769b169254da344.png width=600 height=476 class=img_ev3q /></p>
<ul>
<li class=""><code>V</code> is learnable word vectors that are optimized by minimizing the classification loss with the downstream samples.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=transfer-with-visual-prompt-tuning>Transfer with Visual Prompt Tuning<a href=#transfer-with-visual-prompt-tuning class=hash-link aria-label="Transfer with Visual Prompt Tuning에 대한 직접 링크" title="Transfer with Visual Prompt Tuning에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class="">Transfers VLMs by modulating the input of image encoder.<!-- -->
<ul>
<li class="">VP: adopts learnable image perturbations <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>v</mi></mrow><annotation encoding=application/x-tex>v</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal" style=margin-right:0.03588em>v</span></span></span></span> to modify the input image <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msup><mi>x</mi><mi>I</mi></msup></mrow><annotation encoding=application/x-tex>x^I</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8413em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.07847em>I</span></span></span></span></span></span></span></span></span></span></span> by <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msup><mi>x</mi><mi>I</mi></msup><mo>+</mo><mi>v</mi></mrow><annotation encoding=application/x-tex>x^I + v</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.9247em;vertical-align:-0.0833em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.8413em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:0.07847em>I</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:0.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em></span></span><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal" style=margin-right:0.03588em>v</span></span></span></span>, aiming to adjust <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>v</mi></mrow><annotation encoding=application/x-tex>v</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.4306em></span><span class="mord mathnormal" style=margin-right:0.03588em>v</span></span></span></span> to minimize a recognition loss.</li>
<li class="">RePrompt: integrates retrieval mechanisms into visual prompt tuning, allowing leveraging the knowledge from downstream tasks.</li>
</ul>
</li>
<li class="">enables pixel-level adaptation to downstream tasks, benefiting them greatly especially for dense prediction tasks.</li>
</ul>
<p><img decoding=async loading=lazy alt="Visual Prompt Tuning" src=/assets/images/vlm-visual-prompt-tuning-36a78e501672cf89040235b31cd0c448.png width=632 height=478 class=img_ev3q /></p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=transfer-with-text-visual-prompt-tuning>Transfer with Text-Visual Prompt Tuning<a href=#transfer-with-text-visual-prompt-tuning class=hash-link aria-label="Transfer with Text-Visual Prompt Tuning에 대한 직접 링크" title="Transfer with Text-Visual Prompt Tuning에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class="">modulate the text and image inputs simultaneously, benefiting from joint prompt optimization on multiple modalities.<!-- -->
<ul>
<li class="">UPT: unifies prompt tuning to jointly optimize text and image prompts, demonstrating the complementary nature of the two prompt tuning tasks.</li>
<li class="">MVLPT: explores multi-task vision-language prompt tuning to incorporate cross-task knowledge into text and image prompt tuning.</li>
<li class="">MAPLE: conducts multi-modal prompt tuning by aligning visual prompts with their corresponding language prompts, enabling a mutual promotion between text prompts and image prompts.</li>
<li class="">CAVPT: introduces a cross attention between class-aware visual prompts and text prompts, encouraging the visual prompts to concentrate more on visual concepts.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=transfer-via-feature-adaptation>Transfer via Feature Adaptation<a href=#transfer-via-feature-adaptation class=hash-link aria-label="Transfer via Feature Adaptation에 대한 직접 링크" title="Transfer via Feature Adaptation에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">adapt image or text features with an additional light-weight feature adapter<!-- -->
<ul>
<li class="">Clip-Adapter: inserts several trainable linear layers after CLIP's language and image encoders and optimized them while keeping CLIP architecture and parameters frozen.</li>
<li class="">Tip-adapter: a training-free adapter that directly employs the embeddings of few-shot labelled images as the adapter weights.</li>
<li class="">SVL-Adapter: a self-supervised adapter which employs an additional encoder for self-supervised learning on input images.</li>
</ul>
</li>
<li class="">flexible and effective as its architecture and the insertion manner allow tailoring flexibly for different and complex downstream tasks.</li>
<li class="">requires modifying network architecture and thus can not handle VLMs that have concerns in intellectual property.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=other-transfer-methods>Other Transfer Methods<a href=#other-transfer-methods class=hash-link aria-label="Other Transfer Methods에 대한 직접 링크" title="Other Transfer Methods에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Direct fine-tuning, architecture modification, cross attention<!-- -->
<ul>
<li class="">Wise-FT: combines the weights of a fine-tuned VLM and the original VLM for learning new information from downstream tasks.</li>
<li class="">MaskCLIP: extracts dense image features by modifying the architecture of the CLIP image encoder.</li>
<li class="">VT-CLIP: introduces visual-guided attention to semantically correlate text features with downstream images, leading to a better transfer performance.</li>
<li class="">CALIP: introduces parameter-free attention for effective interaction and communication between visual-guided text features.</li>
<li class="">TaskRes: directly tunes text-based classifier to exploit the old knowledge in the pre-trained VLM.</li>
<li class="">CuPL, VCD: employ large language models like GPT-3 to augment text prompts for learning rich discriminative text information.</li>
</ul>
</li>
</ul>
<p><img decoding=async loading=lazy alt="Feature Adaptation" src=/assets/images/vlm-feature-adaptation-de7cf8b41fcfa8659cc658c703b4dbc5.png width=876 height=498 class=img_ev3q /></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=vlm-knowledge-distillation>VLM Knowledge Distillation<a href=#vlm-knowledge-distillation class=hash-link aria-label="VLM Knowledge Distillation에 대한 직접 링크" title="VLM Knowledge Distillation에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">distils general and robust VLM knowledge to task-specific models without the restriction of VLM architecture, benefiting task-specific designs while tackling various dense prediction tasks.</li>
<li class="">most VLM knowledge distillation methods focus on transferring image-level knowledge to region- or pixel-level tasks such as object detection and semantic segmentation.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=knowledge-distillation-for-object-detection>Knowledge Distillation for Object Detection<a href=#knowledge-distillation-for-object-detection class=hash-link aria-label="Knowledge Distillation for Object Detection에 대한 직접 링크" title="Knowledge Distillation for Object Detection에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">To distill VLM knowledge to enlarge the detector vocabulary</li>
<li class="">To better align image-level and object-level representations<!-- -->
<ul>
<li class="">ViLD: distills VLM knowledge to a two-stage detector whose embedding space is enforced to be consistent with that of CLIP image encoder.</li>
<li class="">HierKD: hierarchical global-local knowledge distillation.</li>
<li class="">RKD: region-based knowledge distillation for better aligning region-level and image-level embeddings.</li>
<li class="">ZSD-YOLO: self-labeling data augmentation for exploiting CLIP for better object detection.</li>
<li class="">OADP: proposal features while transferring contextual knowledge.</li>
<li class="">BARON: uses neighborhood sampling to distill a bag of regions instead of individual regions.</li>
<li class="">RO-ViT: distills information from VLMs for open-vocabulary detection.</li>
</ul>
</li>
<li class="">VLM distillation via prompt learning<!-- -->
<ul>
<li class="">DetPro: a detection prompt technique for learning continuous prompt representations for open-vocabulary object detection.</li>
<li class="">PrompDet: regional prompt learning for aligning word embeddings with regional image embeddings.</li>
<li class="">PB-OVD: trains object detectors with VLM-predicted pseudo bounding boxes.</li>
<li class="">XPM: a robust cross-modal pseudo-labeling strategy that employs VLM-generated pseudo masks for open-vocabulary instance segmentation.</li>
<li class="">P3OVD: prompt-driven self-training that refines the VLM-generated pseudo labels with fine-grained prompt tuning.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=knowledge-distillation-for-semantic-segmentation>Knowledge Distillation for Semantic Segmentation<a href=#knowledge-distillation-for-semantic-segmentation class=hash-link aria-label="Knowledge Distillation for Semantic Segmentation에 대한 직접 링크" title="Knowledge Distillation for Semantic Segmentation에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Leverage VLMs to enlarge the vocabulary of segmentation models, aim to segment pixels described by arbitrary texts. (i.e., any categories of pixels beyond base classes)</li>
<li class="">Tackling the mismatch between image-level and pixel-level representations.<!-- -->
<ul>
<li class="">CLIPSeg: a lightweight transformer decoder to extend CLIP for semantic segmentation.</li>
<li class="">LSeg: maximizes the correlation between CLIP text embeddings and pixel-wise image embedding encoded by segmentation models.</li>
<li class="">ZegCLIP: employs CLIP to generate semantic masks and introduces a relationship descriptor to mitigate overfitting on base classes.</li>
<li class="">MaskCLIP+, SSIW: distill knowledge with VLM-predicted pixel-level pseudo labels.</li>
<li class="">FreeSeg: generates mask proposals first and then performs zero-shot classification for them.</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id=knowledge-distillation-for-weakly-supervised-semantic-segmentation>Knowledge distillation for weakly-supervised semantic segmentation<a href=#knowledge-distillation-for-weakly-supervised-semantic-segmentation class=hash-link aria-label="Knowledge distillation for weakly-supervised semantic segmentation에 대한 직접 링크" title="Knowledge distillation for weakly-supervised semantic segmentation에 대한 직접 링크" translate=no>​</a></h4>
<ul>
<li class="">Leverage both VLMs and weak supervision (e.g., image-level labels) for semantic segmentation.</li>
<li class="">CLIP-ES: employs CLIP to refine the class activation map by designing a softmax function and a class-aware attention-based affinity module for mitigating the category confusion issue.</li>
<li class="">CLIMS: employs CLIP knowledge to generate high-quality class activation maps for better weakly-supervised semantic segmentation.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=performance>Performance<a href=#performance class=hash-link aria-label="Performance에 대한 직접 링크" title="Performance에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">VLM is largely attributed to three factors: Big data, Big Model, and Task-agnostic learning.</li>
<li class="">Limitations<!-- -->
<ul>
<li class="">When data/model size keeps increasing, the performance saturates and further scaling up won’t improve performance</li>
<li class="">Adopting large-scale data in VLM pre-training necessitates extensive computation resources</li>
<li class="">Adopting large models introduces excessive computation and memory overheads in both training and inference</li>
</ul>
</li>
<li class="">Transfer Learning<!-- -->
<ul>
<li class="">can mitigate the domain gaps by learning from task-specific data, being labelled or unlabelled.</li>
<li class="">Supervised <code>></code> few-shot supervised <code>=</code> unsupervised transfer (overfitting but challenging)</li>
</ul>
</li>
<li class="">Knowledge Distillation<!-- -->
<ul>
<li class="">brings clear performance improvement on detection and segmentation tasks</li>
<li class="">introduces general and robust VLM knowledge while benefiting from task-specific designs</li>
</ul>
</li>
<li class="">the development of VLM pre-training for dense visual recognition tasks (on region or pixel-level detection and segmentation) lag far behind.</li>
<li class="">require certain norms in term of training data, networks and downstream tasks.<!-- -->
<ul>
<li class="">VLM transfer: release their codes and do not require intensive computation resources, easing reproduction and benchmarking.</li>
<li class="">VLM pre-training: studied with different data and networks, making benchmarking a very challenging task. also use non-public training data, or require intensive computation resources.</li>
<li class="">VLM knowledge distillation: adopt different task-specific backbones, which complicates benchmarking.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=challenges>Challenges<a href=#challenges class=hash-link aria-label="Challenges에 대한 직접 링크" title="Challenges에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">VLM pre-training<!-- -->
<ul>
<li class=""><strong>Fine-grained vision-language correlation modelling</strong>: can better recognize patches and pixels beyond images, greatly benefiting dense prediction tasks</li>
<li class=""><strong>Unification of vision and language learning</strong>: enables efficient communications across data modalities which can benefit both training effectiveness and training efficiency.</li>
<li class=""><strong>Pre-training VLMs with multiple languages</strong>: could introduce bias in term of cultures and regions and hinder VLM applications in other language areas.</li>
<li class=""><strong>Data-efficient VLMs</strong>: instead of merely learning from each image-text pair, more useful information could be learned with the supervision among image-text pairs.</li>
<li class=""><strong>Pre-training VLMs with LLMs</strong>: employ LLMs to augment the texts in the raw image-text pairs, which provides richer language knowledge and helps better learn vision-language correlation.</li>
</ul>
</li>
<li class="">VLM Transfer Learning<!-- -->
<ul>
<li class=""><strong>Unsupervised VLM transfer</strong>: much lower risk of overfitting than few-shot supervised transfer.</li>
<li class=""><strong>VLM transfer with visual prompt/adapter</strong>: Existing studies focus on text prompt learning. Visual prompt learning or visual adapter, which is complementary to text prompting and can enable pixel-level adaptation in various dense prediction tasks.</li>
<li class=""><strong>Test-time VLM transfer</strong>: Existing studies conduct transfer by fine-tuning VLMs on each downstream task (i.e., prompt learning), leading to repetitive efforts while facing many downstream tasks. Adapting prompts on the fly during inference can circumvent the repetitive training in existing VLM transfer.</li>
<li class=""><strong>VLM transfer with LLMs</strong>: Different from prompt engineering and prompt learning, exploit LLMs to generate text prompts that better describe downstream tasks. This approach is automatic and requires little labelled data.</li>
</ul>
</li>
<li class="">VLM knowledge distillation<!-- -->
<ul>
<li class=""><strong>Knowledge distillation from multiple VLMs</strong>: harvest their synergistic effect by coordinating knowledge distillation from multiple VLMs.</li>
<li class=""><strong>Knowledge distillation for other visual recognition tasks</strong>: leverage the knowledge distilled from VLMs to improve performance on other visual recognition tasks. (instance segmentation, panoptic segmentation, person reidentification)</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=ref>Ref<a href=#ref class=hash-link aria-label="Ref에 대한 직접 링크" title="Ref에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Zhang, J., Huang, J., Jin, S., & Lu, S. (2024). Vision-Language Models for Vision Tasks: A Survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 46(8), 5625–5644. <code>https://doi.org/10.1109/TPAMI.2024.3369699</code></li>
</ul></div><footer class="row docusaurus-mt-lg"><div class=col><b>태그:</b><ul class="tags_jXut padding--none margin-left--sm"><li class=tag_QGVx><a rel=tag title="Vision-Language Models" class="tag_zVej tagRegular_sFm0" href=/tags/vlm/>vlm</a></ul></div></footer></article><article class=margin-bottom--xl><header><h2 class=title_f1Hy><a href=/2025/08/16/introduction-to-ai-003/>IAI +003</a></h2><div class="container_mt6G margin-vert--md"><time datetime=2025-08-15T23:13:08.242Z>2025년 8월 15일</time> · <!-- -->약 5분</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class=avatar__photo-link href=/authors/me/><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/11773683?v=4" alt="Eunkwang Shin"/></a><div class="avatar__intro authorDetails_lV9A"><div class=avatar__name><a href=/authors/me/><span class=authorName_yefp translate=no>Eunkwang Shin</span></a></div><small class=authorTitle_nd0D title=Owner>Owner</small><div class=authorSocials_rSDt><a href=https://www.linkedin.com/in/gracefullight/ target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=LinkedIn><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em preserveAspectRatio=xMidYMid viewBox="0 0 256 256" style=--dark:#0a66c2;--light:#ffffffe6 class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"/></svg></a><a href=https://github.com/gracefullight target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=GitHub><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em viewBox="0 0 256 250" preserveAspectRatio=xMidYMid style=--dark:#000;--light:#fff class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"/></svg></a><a href=mailto:gracefullight.dev@gmail.com target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=Email><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 24 24" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 class=authorSocialIcon_XYv3><path stroke=none d="M0 0h24v24H0z"/><path d="M7.2 12a4.8 4.8 0 1 0 9.6 0 4.8 4.8 0 1 0-9.6 0"/><path d="M16.8 12v1.8a3 3 0 0 0 6 0V12a10.8 10.8 0 1 0-6.6 9.936"/></svg></a></div></div></div></div></div></header><div class=markdown><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=local-search-problem>Local Search Problem<a href=#local-search-problem class=hash-link aria-label="Local Search Problem에 대한 직접 링크" title="Local Search Problem에 대한 직접 링크" translate=no>​</a></h2>
<blockquote>
<p>To find the state that gives the <strong>optimal/best value</strong> of the <strong>evaluation function</strong></p>
</blockquote>
<ul>
<li class="">It can be seen as an <strong>optimization problem</strong>.</li>
<li class="">a computational problem that finds the best solution (a state) that satisfies the given constraints</li>
<li class=""><code>evaluation function === objective function</code></li>
<li class="">Only cares about the optimal solution/best state without considering the paths to reach the best state (the optimal solution)</li>
<li class="">Not systematic</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=feasible-region--solution>Feasible region & solution<a href=#feasible-region--solution class=hash-link aria-label="Feasible region & solution에 대한 직접 링크" title="Feasible region & solution에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class=""><strong>Feasible region</strong>: the set of all possible or candidate solutions which are the solutions that satisfies the problem's constraints</li>
<li class=""><strong>Feasible solution</strong>: a solution in the feasible region</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=search-problem-vs-local-search-problem>Search Problem vs Local Search Problem<a href=#search-problem-vs-local-search-problem class=hash-link aria-label="Search Problem vs Local Search Problem에 대한 직접 링크" title="Search Problem vs Local Search Problem에 대한 직접 링크" translate=no>​</a></h3>
<blockquote>
<p>Path-based vs State-based</p>
</blockquote>
<table><thead><tr><th>Aspects<th>Search Problem<th>Local Search Problem<tbody><tr><td>State<td>All possible states - state-space landscape<td>Range of decision variables and constraints<tr><td>Goal<td>Goal state & goal test<td>Evaluation function & objective function<tr><td>Evaluation<td>Measure closeness to goal - distance/fitness<td>Minimize cost or maximize fitness<tr><td>Transition/Successor<td>Transition function<td>Successor function</table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=discrete--continuous-optimization>Discrete & Continuous Optimization<a href=#discrete--continuous-optimization class=hash-link aria-label="Discrete & Continuous Optimization에 대한 직접 링크" title="Discrete & Continuous Optimization에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class=""><strong>Discrete optimization</strong>: optimization problems where the solution space is discrete (e.g., 8 queens problem)</li>
<li class=""><strong>Continuous optimization</strong>: optimization problems where the solution space is continuous (e.g., real numbers, any value within a range)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=information-needed-for-local-search>Information needed for Local Search<a href=#information-needed-for-local-search class=hash-link aria-label="Information needed for Local Search에 대한 직접 링크" title="Information needed for Local Search에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class=""><strong>All possible states</strong>: state-space landscape</li>
<li class=""><strong>Transition function</strong>: To find neighbor or successor state</li>
<li class=""><strong>Goal state</strong></li>
<li class=""><strong>Objective function</strong>: A way to measure how close to the goal state</li>
<li class=""><strong>Start state</strong></li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=search-state-space>Search state-space<a href=#search-state-space class=hash-link aria-label="Search state-space에 대한 직접 링크" title="Search state-space에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class=""><strong>Global Maximum</strong>: A state that maximizes the objective function over the entire state space</li>
<li class=""><strong>Local Maximum</strong>: A state that maximizes the objective function within a small area around it.</li>
<li class=""><strong>Plateau</strong>: A state such that the objective function is constant in an area around it.<!-- -->
<ul>
<li class=""><strong>Shoulder</strong>: A plateau that has uphill edge.</li>
<li class=""><strong>Flat</strong>: A plateau whose edges go downhill.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=advantages>Advantages<a href=#advantages class=hash-link aria-label="Advantages에 대한 직접 링크" title="Advantages에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">use little memory</li>
<li class="">can often find reasonably good solution in large or infinite search spaces</li>
<li class="">useful for solving pure optimization problems</li>
<li class="">don't need to know the path to the solution.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=hill-climbing>Hill climbing<a href=#hill-climbing class=hash-link aria-label="Hill climbing에 대한 직접 링크" title="Hill climbing에 대한 직접 링크" translate=no>​</a></h2>
<blockquote>
<p>keeps track of one current state and on each iteration moves to the neighboring state with highest value.</p>
</blockquote>
<ul>
<li class=""><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>f</mi><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=false>(</mo><mo>−</mo><mi>c</mi><mi>o</mi><mi>s</mi><mi>t</mi><mo stretchy=false>(</mo><mi>X</mi><mo stretchy=false>)</mo><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>f = max(-cost(X))</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.8889em;vertical-align:-0.1944em></span><span class="mord mathnormal" style=margin-right:0.10764em>f</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class=mopen>(</span><span class=mord>−</span><span class="mord mathnormal">cos</span><span class="mord mathnormal">t</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:0.07847em>X</span><span class=mclose>))</span></span></span></span></li>
<li class="">Steps<!-- -->
<ul>
<li class="">Evaluate the initial stat</li>
<li class="">If it is equal to the goal state, return. Otherwise, continue.</li>
<li class="">Find a neighboring state</li>
<li class="">Evaluate this state. If it is closer to the goal state than before, replace the initial state with this state.</li>
<li class="">Repeat steps 2-4 until it reaches a goal state (local or global maximum) or runs out of time.</li>
</ul>
</li>
<li class="">No search tree, No backtracking, Don't look ahead beyond the current state.<!-- -->
<ul>
<li class="">get stuck due to local maxima, plateaus, or ridges.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=variations-of-hc>Variations of HC<a href=#variations-of-hc class=hash-link aria-label="Variations of HC에 대한 직접 링크" title="Variations of HC에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class=""><strong>Simple HC</strong>: greedy local search which expands the current state and moves on to the best neighbor.</li>
<li class=""><strong>Stochastic HC</strong>: choose randomly among the neighbors going uphill.</li>
<li class=""><strong>First-choice HC</strong>: generate random successor until one is better. Good for states with high numbers of successors.</li>
<li class=""><strong>Random restart</strong>: conducts a series of hill climbing searches from random initial states until a goal state is found.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=simulated-annealing>Simulated Annealing<a href=#simulated-annealing class=hash-link aria-label="Simulated Annealing에 대한 직접 링크" title="Simulated Annealing에 대한 직접 링크" translate=no>​</a></h2>
<blockquote>
<p>based upon the annealing process to model the search process for finding an optimal solution to an optimisation problem</p>
</blockquote>
<ul>
<li class=""><strong>annealing schedule</strong>, <strong>temperature</strong>, <strong>energy</strong></li>
<li class="">finds the <strong>minimal value</strong> of the objective function (energy function)</li>
<li class="">starts with a high temperature and then gradually reduces the temperature</li>
<li class=""><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>P</mi><mo>=</mo><msup><mi>e</mi><mrow><mo>−</mo><mi mathvariant=normal>Δ</mi><mi>E</mi><mi mathvariant=normal>/</mi><mi>k</mi><mi>T</mi></mrow></msup></mrow><annotation encoding=application/x-tex>P = e^{-\Delta E / kT}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.888em></span><span class=mord><span class="mord mathnormal">e</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:0.888em><span style=top:-3.063em;margin-right:0.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">Δ</span><span class="mord mathnormal mtight" style=margin-right:0.05764em>E</span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style=margin-right:0.03148em>k</span><span class="mord mathnormal mtight" style=margin-right:0.13889em>T</span></span></span></span></span></span></span></span></span></span></span></span>
<ul>
<li class=""><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=normal>Δ</mi><mi>E</mi></mrow><annotation encoding=application/x-tex>\Delta E</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class=mord>Δ</span><span class="mord mathnormal" style=margin-right:0.05764em>E</span></span></span></span>: how bad the new state is compared to the old state</li>
<li class=""><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>T</mi></mrow><annotation encoding=application/x-tex>T</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6833em></span><span class="mord mathnormal" style=margin-right:0.13889em>T</span></span></span></span>: temperature is getting lower over time</li>
<li class=""><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>k</mi></mrow><annotation encoding=application/x-tex>k</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.6944em></span><span class="mord mathnormal" style=margin-right:0.03148em>k</span></span></span></span>: a scaling factor</li>
</ul>
</li>
<li class="">Swap condition: <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi mathvariant=normal>Δ</mi><mi>E</mi><mo>&lt;</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding=application/x-tex>\Delta E &lt;= 0</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7224em;vertical-align:-0.0391em></span><span class=mord>Δ</span><span class="mord mathnormal" style=margin-right:0.05764em>E</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>&lt;=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6444em></span><span class=mord>0</span></span></span></span> or <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mrow><mo>−</mo><mi mathvariant=normal>Δ</mi><mi>E</mi><mi mathvariant=normal>/</mi><mi>k</mi><mi>T</mi></mrow><mo>></mo><mtext>random</mtext></mrow><annotation encoding=application/x-tex>{-\Delta E / kT} > \text{random}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord><span class=mord>−</span><span class=mord>Δ</span><span class="mord mathnormal" style=margin-right:0.05764em>E</span><span class=mord>/</span><span class="mord mathnormal" style=margin-right:0.03148em>k</span><span class="mord mathnormal" style=margin-right:0.13889em>T</span></span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>></span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:0.6944em></span><span class="mord text"><span class=mord>random</span></span></span></span></span></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=evolutionary-algorithms>Evolutionary algorithms<a href=#evolutionary-algorithms class=hash-link aria-label="Evolutionary algorithms에 대한 직접 링크" title="Evolutionary algorithms에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Local beam search</li>
<li class="">Stochastic beam search</li>
<li class=""><strong>Genetic algorithms</strong></li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=characteristics>Characteristics<a href=#characteristics class=hash-link aria-label="Characteristics에 대한 직접 링크" title="Characteristics에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">size of the population</li>
<li class="">representation of each individual</li>
<li class="">mixing number</li>
<li class="">selection process for selecting the individuals who will become the parents of the next generation</li>
<li class="">recombination procedure</li>
<li class="">mutation rate</li>
<li class="">makeup of the next generation</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=genetic-algorithm>Genetic algorithm<a href=#genetic-algorithm class=hash-link aria-label="Genetic algorithm에 대한 직접 링크" title="Genetic algorithm에 대한 직접 링크" translate=no>​</a></h3>
<blockquote>
<p>It uses operators, such reproduction, crossover and mutation, inspired by the natural evolutionary principles.</p>
</blockquote>
<ul>
<li class=""><strong>State</strong>: is represented by an individual in a population. Traditional representation is a chromosome</li>
<li class=""><strong>Objective function</strong>: is used to evaluate the fitness of an individual (= fitness function, 적합도 함수)</li>
<li class=""><strong>Successor function</strong>: consists of three operators: reproduction, crossover, and mutation</li>
<li class=""><strong>Solution</strong>: is found through evolution from one generation to another generation</li>
</ul>
<!-- -->
<p><img decoding=async loading=lazy alt="Genetic Algorithm" src=/assets/images/genetic-algorithm-db5ac52fb262d55d999eff1f47439e1b.png width=1730 height=430 class=img_ev3q /></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=roulette-wheel-selection>Roulette Wheel Selection<a href=#roulette-wheel-selection class=hash-link aria-label="Roulette Wheel Selection에 대한 직접 링크" title="Roulette Wheel Selection에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class=""><strong>Compute total fitness</strong> of all individuals.<!-- -->
<ul>
<li class="">Example: A=30, B=20, C=40, D=10 → Total = 100.</li>
</ul>
</li>
<li class=""><strong>Calculate probability</strong> of each individual being selected<!-- -->
<ul>
<li class="">Formula: <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>P</mi><mo stretchy=false>(</mo><mi>i</mi><mo stretchy=false>)</mo><mo>=</mo><mfrac><mrow><mi>f</mi><mi>i</mi><mi>t</mi><mi>n</mi><mi>e</mi><mi>s</mi><mi>s</mi><mo stretchy=false>(</mo><mi>i</mi><mo stretchy=false>)</mo></mrow><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi mathvariant=normal>_</mi><mi>f</mi><mi>i</mi><mi>t</mi><mi>n</mi><mi>e</mi><mi>s</mi><mi>s</mi></mrow></mfrac></mrow><annotation encoding=application/x-tex>P(i) = \frac{fitness(i)}{total\_fitness}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class="mord mathnormal" style=margin-right:0.13889em>P</span><span class=mopen>(</span><span class="mord mathnormal">i</span><span class=mclose>)</span><span class=mspace style=margin-right:0.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em></span></span><span class=base><span class=strut style=height:1.572em;vertical-align:-0.562em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.01em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style=margin-right:0.01968em>l</span><span class="mord mtight" style=margin-right:0.02778em>_</span><span class="mord mathnormal mtight" style=margin-right:0.10764em>f</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">ess</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:0.04em></span></span><span style=top:-3.485em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:0.10764em>f</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">ess</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:0.562em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>
<ul>
<li class="">A = 30/100 = 0.30</li>
<li class="">B = 20/100 = 0.20</li>
<li class="">C = 40/100 = 0.40</li>
<li class="">D = 10/100 = 0.10</li>
</ul>
</li>
</ul>
</li>
<li class=""><strong>Convert to cumulative probabilities</strong>
<ul>
<li class="">P4 = 0.10</li>
<li class="">P4 + P3 = 0.50</li>
<li class="">P4 + P3 + P2 = 0.90</li>
<li class="">P4 + P3 + P2 + P1 = 1.00</li>
</ul>
</li>
<li class=""><strong>Generate a random number</strong> between 0 and 1.</li>
<li class="">Select an individual based on the random number and cumulative probabilities.</li>
</ul>
<p><img decoding=async loading=lazy alt="Roulette Wheel Selection" src=/assets/images/roulette-wheel-selection-d6c6fabff2f28f3ba08382b9a4727c13.png width=1333 height=570 class=img_ev3q /></p>
<ul>
<li class="">⚫ random = 0.07 → falls in P4 <code>[0, 0.10)</code></li>
<li class="">🔺 random = 0.37 → falls in P3 <code>[0.10, 0.50)</code></li>
<li class="">⬟ random = 0.82 → falls in P2 <code>[0.50, 0.90)</code></li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=applications-of-ga>Applications of GA<a href=#applications-of-ga class=hash-link aria-label="Applications of GA에 대한 직접 링크" title="Applications of GA에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class=""><strong>Parameter tuning</strong>: optimize the parameters in NN</li>
<li class=""><strong>Planning</strong>: economic dispatch, train timetabling</li>
<li class=""><strong>Design & Control problems</strong>: robotic control, adaptive control systems</li>
<li class="">Successful use of GA requires careful engineering of the <strong>representation</strong></li>
</ul></div><footer class="row docusaurus-mt-lg"><div class=col><b>태그:</b><ul class="tags_jXut padding--none margin-left--sm"><li class=tag_QGVx><a rel=tag class="tag_zVej tagRegular_sFm0" href=/tags/iai/>iai</a></ul></div></footer></article><article class=margin-bottom--xl><header><h2 class=title_f1Hy><a href=/2025/08/14/fundamentals-of-data-analytics-003/>FDA +003</a></h2><div class="container_mt6G margin-vert--md"><time datetime=2025-08-14T06:13:20.434Z>2025년 8월 14일</time> · <!-- -->약 8분</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class=avatar__photo-link href=/authors/me/><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/11773683?v=4" alt="Eunkwang Shin"/></a><div class="avatar__intro authorDetails_lV9A"><div class=avatar__name><a href=/authors/me/><span class=authorName_yefp translate=no>Eunkwang Shin</span></a></div><small class=authorTitle_nd0D title=Owner>Owner</small><div class=authorSocials_rSDt><a href=https://www.linkedin.com/in/gracefullight/ target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=LinkedIn><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em preserveAspectRatio=xMidYMid viewBox="0 0 256 256" style=--dark:#0a66c2;--light:#ffffffe6 class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"/></svg></a><a href=https://github.com/gracefullight target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=GitHub><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em viewBox="0 0 256 250" preserveAspectRatio=xMidYMid style=--dark:#000;--light:#fff class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"/></svg></a><a href=mailto:gracefullight.dev@gmail.com target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=Email><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 24 24" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 class=authorSocialIcon_XYv3><path stroke=none d="M0 0h24v24H0z"/><path d="M7.2 12a4.8 4.8 0 1 0 9.6 0 4.8 4.8 0 1 0-9.6 0"/><path d="M16.8 12v1.8a3 3 0 0 0 6 0V12a10.8 10.8 0 1 0-6.6 9.936"/></svg></a></div></div></div></div></div></header><div class=markdown><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=crisp-dm>CRISP-DM<a href=#crisp-dm class=hash-link aria-label="CRISP-DM에 대한 직접 링크" title="CRISP-DM에 대한 직접 링크" translate=no>​</a></h2>
<blockquote>
<p>CRISP-DM (Cross-Industry Standard Process for Data Mining)</p>
</blockquote>
<ol>
<li class="">Business understanding</li>
<li class="">Data understanding</li>
<li class="">Data preparation</li>
<li class="">Modeling</li>
<li class="">Evaluation</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=business-understanding>Business understanding<a href=#business-understanding class=hash-link aria-label="Business understanding에 대한 직접 링크" title="Business understanding에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Determine business objectives</li>
<li class="">Assess situation</li>
<li class="">Determine data mining goals</li>
<li class="">Produce project plan</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=data-understanding>Data understanding<a href=#data-understanding class=hash-link aria-label="Data understanding에 대한 직접 링크" title="Data understanding에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Collect initial data</li>
<li class="">Describe data</li>
<li class="">Explore data</li>
<li class="">Verify data quality</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=data-preperation>Data preperation<a href=#data-preperation class=hash-link aria-label="Data preperation에 대한 직접 링크" title="Data preperation에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Select data</li>
<li class="">Clean data</li>
<li class="">Consturct data</li>
<li class="">Integrate data</li>
<li class="">Format data</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=modeling>Modeling<a href=#modeling class=hash-link aria-label="Modeling에 대한 직접 링크" title="Modeling에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Select modeling technique</li>
<li class="">Generate test design</li>
<li class="">Build model</li>
<li class="">Assess model</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=evaluation>Evaluation<a href=#evaluation class=hash-link aria-label="Evaluation에 대한 직접 링크" title="Evaluation에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Evaludate results</li>
<li class="">Review process</li>
<li class="">Determine next steps</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=deployment>Deployment<a href=#deployment class=hash-link aria-label="Deployment에 대한 직접 링크" title="Deployment에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Plan development</li>
<li class="">Plan monitoring & maintenance</li>
<li class="">Produce final report</li>
<li class="">Review project</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=instance--attributes>Instance & Attributes<a href=#instance--attributes class=hash-link aria-label="Instance & Attributes에 대한 직접 링크" title="Instance & Attributes에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Instance: the terms associated with specific objects. Instances are described by a set of values for the features.</li>
<li class="">Attributes: the collection of features of the object that are maintained in a dataset.</li>
<li class="">Object: a collection of features about which measurements can be taken.<!-- -->
<ul>
<li class="">Car: fuel consumption, cylinders, horsepower...</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=qualitative--quantitative-data>Qualitative & Quantitative data<a href=#qualitative--quantitative-data class=hash-link aria-label="Qualitative & Quantitative data에 대한 직접 링크" title="Qualitative & Quantitative data에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Qualitative data: <strong>less structured</strong>, <strong>non-statistical</strong>, <strong>measured using other descriptors and identifiers</strong>
<ul>
<li class="">white, heavy, wild...</li>
</ul>
</li>
<li class="">Quantitative data: <strong>statistical</strong>, <strong>measured using hard numbers.</strong>
<ul>
<li class="">130cm, 400kg, 4 legs...</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=discrete--continuous-quantitative-data>Discrete & Continuous (Quantitative) data<a href=#discrete--continuous-quantitative-data class=hash-link aria-label="Discrete & Continuous (Quantitative) data에 대한 직접 링크" title="Discrete & Continuous (Quantitative) data에 대한 직접 링크" translate=no>​</a></h3>
<!-- -->
<ul>
<li class="">Discrete data: <strong>fixed, round numbers</strong>, <strong>countable</strong>
<ul>
<li class="">number of legs, count of aeroplane depatures, number of times a person commutes for a job in a week</li>
</ul>
</li>
<li class="">Continuous data: <strong>measured over time intervals</strong>
<ul>
<li class="">weight, solar irradiation, temperature of a room</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=summary>Summary<a href=#summary class=hash-link aria-label="Summary에 대한 직접 링크" title="Summary에 대한 직접 링크" translate=no>​</a></h3>
<table><thead><tr><th>Qualitative<th>Quantitiative (discrete)<th>Quantitiative (continuous)<tbody><tr><td>Title<td>Duration<td>Rating<tr><td>Production Country<td>Release Year<td><tr><td>Director<td><td><tr><td>Genres<td><td><tr><td>Description<td><td></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=categorizing-attributees>Categorizing attributees<a href=#categorizing-attributees class=hash-link aria-label="Categorizing attributees에 대한 직접 링크" title="Categorizing attributees에 대한 직접 링크" translate=no>​</a></h2>
<table><thead><tr><th>항목<th><strong>Nominal (categorical)</strong><th><strong>Ordinal</strong><th><strong>Interval</strong><th><strong>Ratio</strong><tbody><tr><td><strong>정의</strong><td>값이 라벨·이름 역할만 함. 순서 없음.<td>값 사이에 순서 있음. 간격은 정의되지 않음.<td>순서 + 고정·동일한 단위(간격). 절대 0 없음.<td>Interval 속성 + 절대적 0 있음. 차이와 비율 모두 의미 있음.<tr><td><strong>예시</strong><td>머리카락 색 <code>{blonde, brown, ginger}</code><br/>우편번호<br/>산업코드, 연구분야 코드<br/>Blood type, License number<td>키: <code>tall > average > short</code><br/>체중: <code>light &lt; average &lt; heavy</code><br/>Star ratings, Tshirt sizes<td>키(cm), 몸무게(kg) (원문 기준)<br/>12시간제 시각(차이 비교)<br/>시간 간격(5분~10분)<br/>Waist size, Time<td>나이(년)<br/>소득(천 달러)<br/>켈빈 온도<br/>금액, 개수, 질량, 길이, 전류<br/>Body weight, Medicine dosage<tr><td><strong>예시</strong><td>머리카락 색 <code>{blonde, brown, ginger}</code>, 우편번호, 산업코드/연구분야 코드, Blood type, License number<td>키: <code>tall > average > short</code>, 체중: <code>light &lt; average &lt; heavy</code>, Star ratings, Tshirt sizes<td>키(cm), 몸무게(kg) (원문 기준), 12시간제 시각(차이 비교), 시간 간격(5분~10분), Waist size, Time<td>나이(년), 소득(천 달러), 켈빈 온도, 금액, 개수, 질량, 길이, 전류, Body weight, Medicine dosage<tr><td><strong>허용 비교</strong><td><code>=, ≠</code><td><code>=, ≠, &lt;, ></code><td><code>=, ≠, &lt;, >, +, −</code><td><code>=, ≠, &lt;, >, +, −, ×, ÷</code><tr><td><strong>연산 / 분석</strong><td>Mode(최빈값)<br/>Entropy(불확실성 측정)<br/>Contingency table(교차표)<br/>Correlation(Chi-squared test of independence)<br/>Chi-squared test<td>Median<br/>Percentiles<br/>Rank correlation(Spearman)<br/>Run tests(Mann–Whitney U, Wilcoxon)<br/>Sign tests<td>Mean<br/>Standard Deviation<br/>Pearson correlation<br/>T-test<br/>F-test(ANOVA)<td>Geometric Mean<br/>Harmonic Mean<br/>Percent variation(CV)<tr><td><strong>설명</strong><td>통계적 평균·표준편차 무의미<td>순위는 비교 가능하지만 간격·크기 비교 불가.<br/>중앙값·순위기반 통계 적합.<td>간격 일정 → +, − 가능.<br/>절대 0 없음 → 비율 해석 불가.<td>절대 0 → 모든 연산 가능.<br/>비율·곱셈 해석 가능.<tr><td><strong>변수 특징</strong><td>Named variables<td>Named & Ordered variables<td>Named & Ordered & Distance between variables<td>Named & Ordered & Distance between variables & Makes sense to multiply/divide<tr><td><strong>Analysis Method</strong><td>Frequency<td>Frequency<br/>Median and percentiles<td>Frequency<br/>Median and percentiles<br/>Add or Subtract<br/>Mean, standard deviation, standard error of the mean<td>Frequency<br/>Median and percentiles<br/>Add or Subtract<br/>Mean, standard deviation, standard error of the mean<br/>Ratio<tr><td><strong>데이터 유형</strong><td>Qualitative<td>Qualitative<td>Quantitative<td>Quantitative</table>
<table><thead><tr><th>Attribute Type<th>Description<th>Examples<th>Operations<tbody><tr><td><strong>Nominal</strong><td>The values of a nominal attribute are just different names, i.e. nominal attributes provide only enough information to distinguish one object from another. (<code>=, ≠</code>)<td>post codes, employee ID numbers, eye colour, sex: <code>{ male, female }</code><td>mode, entropy, contingency, correlation, chi squared test<tr><td><strong>Ordinal</strong><td>The values of an ordinal attribute provide enough information to order objects. (<code>&lt;, ></code>)<td>hardness of minerals, <code>{ good, better, best }</code>, grades, street numbers<td>median, percentiles, rank correlation, run tests, sign tests<tr><td><strong>Interval</strong><td>For interval attributes, the differences between values are meaningful, i.e. a unit of measurement exists. (<code>+, −</code>)<td>calendar dates, temperature in Celsius or Fahrenheit<td>mean, standard deviation, Pearson’s correlation, t and F tests<tr><td><strong>Ratio</strong><td>For ratio variables both differences and ratios are meaningful. (<code>×, ÷</code>)<td>temperature in Kelvin, monetary quantities, counts, age, mass, length, electrical current<td>geometric mean, harmonic mean, percent variation</table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=structured--unstructured-data>Structured & Unstructured Data<a href=#structured--unstructured-data class=hash-link aria-label="Structured & Unstructured Data에 대한 직접 링크" title="Structured & Unstructured Data에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Structured Data: which has an associated fixed data structure.<!-- -->
<ul>
<li class="">Relational table</li>
<li class="">Manageable</li>
</ul>
</li>
<li class="">Unstructured Data: which is expressed in natural language and no specific structure and domain types are defined.<!-- -->
<ul>
<li class="">Documents and sounds.</li>
</ul>
</li>
<li class="">Semi-structured Data: the format is not fixed and has some degree of flexibility.<!-- -->
<ul>
<li class="">XML, JSON</li>
<li class="">emails, text data, image, video and sound, zipped files, web pages.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=curse-of-dimensionality>Curse of dimensionality<a href=#curse-of-dimensionality class=hash-link aria-label="Curse of dimensionality에 대한 직접 링크" title="Curse of dimensionality에 대한 직접 링크" translate=no>​</a></h2>
<blockquote>
<p>The explosive nature of increasing data dimensions and its resulting exponential increase in computational efforts required for its processing and/or analysis.</p>
</blockquote>
<ul>
<li class="">Characteristics of structured data<!-- -->
<ul>
<li class="">Dimensionality: Datasets with higher numbers of attributes have more dimensions, challenging to work with high dimensional data.</li>
<li class="">Sparsity: A dataset termed spare data or having the property of sparsity, which contains many zeros values for most of the attributes.</li>
<li class="">Resolution: The patterns depend on the scale or level of resolution.</li>
</ul>
</li>
<li class="">Real life data is usually in a lower dimensional manifold<!-- -->
<ul>
<li class="">many dimensions can be either ignored or the dimensionality can be reduced.</li>
</ul>
</li>
<li class="">Local smoothness: small changes in input values give small changes in output values.<!-- -->
<ul>
<li class="">Local interpolation to make predictions.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=datasets>Datasets<a href=#datasets class=hash-link aria-label="Datasets에 대한 직접 링크" title="Datasets에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Record Data<!-- -->
<ul>
<li class="">Data Matrix</li>
<li class="">Document data: a special type of data matrix where the attributes are of the same type and are asymmetric.</li>
<li class="">Transaction data: a special type of record data. Each record involves a set of items. Most often, the attributes are binary, indicating whether or not an item was purchased.</li>
</ul>
</li>
<li class="">Graph data<!-- -->
<ul>
<li class="">World wide web, Molecular structures (Simplified molecular-inputline-entry system, SMILES)</li>
</ul>
</li>
<li class="">Ordered data: sequence data, this is a sequence of individual entities, such as a sequence of words or letters.<!-- -->
<ul>
<li class="">Spatial data</li>
<li class="">Temporal data</li>
<li class="">Sequential data</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=data-collection>Data collection<a href=#data-collection class=hash-link aria-label="Data collection에 대한 직접 링크" title="Data collection에 대한 직접 링크" translate=no>​</a></h2>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=quality>Quality<a href=#quality class=hash-link aria-label="Quality에 대한 직접 링크" title="Quality에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Missing values: The data was not collected (e.g. age), or some attributes may not be applicable in all cases (e.g. annual income for children).</li>
<li class="">Empty values: Unlike missing values, an empty value is the one that has no actual value, whereas a missing value has an actual value but it is missing somehow.</li>
<li class="">Noise: The modification of actual values.</li>
<li class="">Outlier: A single or very low frequency occurrence of a value of an attribute that is far from the bulk of attribute values.</li>
<li class="">Duplicate data: The same data is recorded multiple times.</li>
<li class="">Inconsistent formats: When the same set of data appears in multiple tables from different inputs.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=data-auditing>Data auditing<a href=#data-auditing class=hash-link aria-label="Data auditing에 대한 직접 링크" title="Data auditing에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">attributes</li>
<li class="">measured values</li>
<li class="">comments</li>
<li class="">attribute type</li>
<li class="">operations we can do</li>
<li class="">data type (knime/py)</li>
<li class="">missing value</li>
<li class="">any comments about qualities</li>
</ul>
<table><thead><tr><th>attributes<th>measured values<th>comments<th>attribute type<th>operations we can do<th>Data type (knime/python)<th>missing value<th>Any comments about qualities<tbody><tr><td>fixed acidity<td><code>[3.8, 15.9]</code><td>continuous number<td>ratio<td>all arithmetic<td>float<td>N/A<td><tr><td>volatile acidity<td><code>[0.08, 1.58]</code><td>continuous number<td>ratio<td>all arithmetic<td>float<td>N/A<td><tr><td>citric acid<td><code>[0, 1.66]</code><td>continuous number<td>ratio<td>all arithmetic<td>float<td>N/A<td><tr><td>residual sugar<td><code>[0.6, 65.8]</code><td>continuous number<td>ratio<td>all arithmetic<td>float<td>N/A<td><tr><td>chlorides<td><code>[0.009, 0.611]</code><td>continuous number<td>ratio<td>all arithmetic<td>float<td>N/A<td><tr><td>free sulfur dioxide<td><code>[1, 289]</code><td>continuous number<td>ratio<td>all arithmetic<td>int<td>N/A<td><tr><td>total sulfur dioxide<td><code>[6, 440]</code><td>continuous number<td>ratio<td>all arithmetic<td>int<td>N/A<td><tr><td>density<td><code>[0.98711, 1.03898]</code><td>continuous number<td>ratio<td>all arithmetic<td>float<td>N/A<td><tr><td>pH<td><code>[2.72, 4.01]</code><td>continuous number<td>interval<td>order, arithmetic<td>float<td>N/A<td><tr><td>sulphates<td><code>[0.22, 2]</code><td>continuous number<td>ratio<td>all arithmetic<td>float<td>N/A<td><tr><td>alcohol<td><code>[8, 14.9]</code><td>continuous number<td>ratio<td>all arithmetic<td>float<td>N/A<td><tr><td>quality<td><code>[extremely dissatisfied, extremely satisfied, moderately dissatisfied, moderately satisfied, neutral, slightly dissatisfied, slightly satisfied]</code><td>distributed<td>ordinal<td>order, counting<td>str<td>N/A<td><tr><td>color<td><code>[white, red]</code><td>distributed<td>nominal<td>counting<td>str<td>N/A<td></table></div><footer class="row docusaurus-mt-lg"><div class=col><b>태그:</b><ul class="tags_jXut padding--none margin-left--sm"><li class=tag_QGVx><a rel=tag class="tag_zVej tagRegular_sFm0" href=/tags/fda/>fda</a></ul></div></footer></article><article class=margin-bottom--xl><header><h2 class=title_f1Hy><a href=/vocab/vocab-ai-004/>Vocabulary for AI +004</a></h2><div class="container_mt6G margin-vert--md"><time datetime=2025-08-14T05:01:26.639Z>2025년 8월 14일</time> · <!-- -->약 4분</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class=avatar__photo-link href=/authors/me/><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/11773683?v=4" alt="Eunkwang Shin"/></a><div class="avatar__intro authorDetails_lV9A"><div class=avatar__name><a href=/authors/me/><span class=authorName_yefp translate=no>Eunkwang Shin</span></a></div><small class=authorTitle_nd0D title=Owner>Owner</small><div class=authorSocials_rSDt><a href=https://www.linkedin.com/in/gracefullight/ target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=LinkedIn><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em preserveAspectRatio=xMidYMid viewBox="0 0 256 256" style=--dark:#0a66c2;--light:#ffffffe6 class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"/></svg></a><a href=https://github.com/gracefullight target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=GitHub><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em viewBox="0 0 256 250" preserveAspectRatio=xMidYMid style=--dark:#000;--light:#fff class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"/></svg></a><a href=mailto:gracefullight.dev@gmail.com target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=Email><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 24 24" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 class=authorSocialIcon_XYv3><path stroke=none d="M0 0h24v24H0z"/><path d="M7.2 12a4.8 4.8 0 1 0 9.6 0 4.8 4.8 0 1 0-9.6 0"/><path d="M16.8 12v1.8a3 3 0 0 0 6 0V12a10.8 10.8 0 1 0-6.6 9.936"/></svg></a></div></div></div></div></div></header><div class=markdown><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=vocabulary--expressions>Vocabulary & Expressions<a href=#vocabulary--expressions class=hash-link aria-label="Vocabulary & Expressions에 대한 직접 링크" title="Vocabulary & Expressions에 대한 직접 링크" translate=no>​</a></h2>
<table><thead><tr><th>Term/Expression<th>Definition<th>Simpler Paraphrase<th>Meaning<tbody><tr><td><a href=https://dictionary.cambridge.org/dictionary/english/relax target=_blank rel="noopener noreferrer" class="">relax</a><td>to make a rule or control less severe<td>to make less strict or severe<td>완화하다, 느슨하게 하다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/reconstruct target=_blank rel="noopener noreferrer" class="">reconstruct</a><td>to build or form again<td>to rebuild<td>재구성하다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/reside target=_blank rel="noopener noreferrer" class="">reside</a><td>to live in a place; to exist or be present<td>to live; to be located<td>위치하다, 존재하다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/lay-out target=_blank rel="noopener noreferrer" class="">lay out</a><td>to arrange or plan something in a clear and organized way<td>to arrange<td>배치하다, 설계하다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/resemble target=_blank rel="noopener noreferrer" class="">resemble</a><td>to look like or be similar to someone or something<td>to look like<td>닮다, 유사하다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/amnesia target=_blank rel="noopener noreferrer" class="">amnesia</a><td>a condition in which a person is unable to remember things<td>memory loss<td>기억상실증<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/vicinity target=_blank rel="noopener noreferrer" class="">vicinity</a><td>the area near or surrounding a particular place<td>nearby area<td>인근, 근처<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/schematically target=_blank rel="noopener noreferrer" class="">schematically</a><td>in a way that represents the main features or relationships of something in a simple and clear form<td>in a simplified way<td>도식적으로<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/superimpose target=_blank rel="noopener noreferrer" class="">superimpose</a><td>to place or lay something over something else<td>to overlay<td>겹쳐 놓다, 중첩하다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/plateaus target=_blank rel="noopener noreferrer" class="">plateaus</a><td>a state of little or no change following a period of activity or progress<td>a period of stability<td>정체기, 안정기, 고원<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/wander target=_blank rel="noopener noreferrer" class="">wander</a><td>to move around without a fixed course, aim, or goal<td>to roam<td>방황하다, 헤매다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/consecutive target=_blank rel="noopener noreferrer" class="">consecutive</a><td>following continuously; in unbroken or logical sequence<td>sequential<td>연속적인<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/converge target=_blank rel="noopener noreferrer" class="">converge</a><td>to come together from different directions<td>to meet<td>수렴하다, 모이다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/adage target=_blank rel="noopener noreferrer" class="">adage</a><td>a saying or proverb expressing a common truth<td>a wise saying<td>격언, 속담<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/porcupine target=_blank rel="noopener noreferrer" class="">porcupine</a><td>a large rodent with sharp quills on its back<td>a spiny animal<td>호저<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/stumble target=_blank rel="noopener noreferrer" class="">stumble</a><td>to trip or lose balance while walking or running<td>to trip<td>비틀거리다, 넘어지다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/metallurgy target=_blank rel="noopener noreferrer" class="">metallurgy</a><td>the science and technology of metals<td>metal science<td>금속공학<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/crystalline target=_blank rel="noopener noreferrer" class="">crystalline</a><td>having the structure and form of a crystal<td>crystal-like<td>결정질의<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/crevice target=_blank rel="noopener noreferrer" class="">crevice</a><td>a narrow opening or fissure<td>a crack<td>틈, 균열<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/bumpy target=_blank rel="noopener noreferrer" class="">bumpy</a><td>having an uneven or jolting surface<td>uneven<td>울퉁불퉁한<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/dislodge target=_blank rel="noopener noreferrer" class="">dislodge</a><td>to remove or force out from a position<td>to remove<td>제거하다, 떼어내다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/exponentially target=_blank rel="noopener noreferrer" class="">exponentially</a><td>in a way that increases rapidly and significantly<td>rapidly<td>기하급수적으로<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/halt target=_blank rel="noopener noreferrer" class="">halt</a><td>to stop or pause something<td>to stop<td>중단하다, 멈추다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/unfruitful target=_blank rel="noopener noreferrer" class="">unfruitful</a><td>not producing good results<td>unproductive<td>결실이 없는<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/analogous target=_blank rel="noopener noreferrer" class="">analogous</a><td>similar in some way<td>comparable<td>유사한<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/proportional target=_blank rel="noopener noreferrer" class="">proportional</a><td>corresponding in size or amount to something else<td>relative<td>비례하는<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/retained target=_blank rel="noopener noreferrer" class="">retained</a><td>kept or continued to have<td>kept<td>유지된<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/in-accordance-with target=_blank rel="noopener noreferrer" class="">in accordance with</a><td>following or obeying a rule, law, or wish<td>according to<td>~에 따라, ~에 일치하여<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/constitute target=_blank rel="noopener noreferrer" class="">constitute</a><td>to be a part of something<td>to form<td>구성하다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/permute target=_blank rel="noopener noreferrer" class="">permute</a><td>to change the order or arrangement of something<td>to rearrange<td>순열하다, 배열을 바꾸다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/chromosome target=_blank rel="noopener noreferrer" class="">chromosome</a><td>a thread-like structure of nucleic acids and protein found in the nucleus of most living cells<td>genetic structure<td>염색체<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/auxiliary target=_blank rel="noopener noreferrer" class="">auxiliary</a><td>providing supplementary or additional help and support<td>supplementary<td>보조의<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/discriminative target=_blank rel="noopener noreferrer" class="">discriminative</a><td>able to distinguish or differentiate<td>distinguishing<td>구별 가능한<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/exploit target=_blank rel="noopener noreferrer" class="">exploit</a><td>to make full use of and benefit from something<td>to utilize<td>활용하다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/perturbation target=_blank rel="noopener noreferrer" class="">perturbation</a><td>a small change or variation<td>a disturbance<td>교란<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/modulate target=_blank rel="noopener noreferrer" class="">modulate</a><td>to adjust or alter the intensity or frequency of something<td>to adjust<td>조절하다, 변조하다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/retrieval target=_blank rel="noopener noreferrer" class="">retrieval</a><td>the process of getting stored information from a computer<td>search<td>검색<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/leverage target=_blank rel="noopener noreferrer" class="">leverage</a><td>to use something to maximum advantage<td>to utilize<td>활용하다<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/discrepancy target=_blank rel="noopener noreferrer" class="">discrepancy</a><td>a difference or inconsistency<td>difference<td>불일치<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/heterogeneity target=_blank rel="noopener noreferrer" class="">heterogeneity</a><td>the quality or state of being diverse in character or content<td>diversity<td>이질성<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/pseudonymization target=_blank rel="noopener noreferrer" class="">pseudonymization</a><td>the process of replacing private identifiers with fake identifiers or pseudonyms<td>anonymization<td>가명화<tr><td><a href=https://dictionary.cambridge.org/dictionary/english/denote target=_blank rel="noopener noreferrer" class="">denote</a><td>to be a sign of something<td>to signify<td>나타내다, 의미하다</table></div><footer class="row docusaurus-mt-lg"><div class=col><b>태그:</b><ul class="tags_jXut padding--none margin-left--sm"><li class=tag_QGVx><a rel=tag title="Life Logging" class="tag_zVej tagRegular_sFm0" href=/tags/me/>me</a></ul></div></footer></article><article class=margin-bottom--xl><header><h2 class=title_f1Hy><a href=/2025/08/11/fundamentals-of-software-development-003/>FSD +003</a></h2><div class="container_mt6G margin-vert--md"><time datetime=2025-08-11T05:27:23.544Z>2025년 8월 11일</time> · <!-- -->약 4분</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class=avatar__photo-link href=/authors/me/><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/11773683?v=4" alt="Eunkwang Shin"/></a><div class="avatar__intro authorDetails_lV9A"><div class=avatar__name><a href=/authors/me/><span class=authorName_yefp translate=no>Eunkwang Shin</span></a></div><small class=authorTitle_nd0D title=Owner>Owner</small><div class=authorSocials_rSDt><a href=https://www.linkedin.com/in/gracefullight/ target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=LinkedIn><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em preserveAspectRatio=xMidYMid viewBox="0 0 256 256" style=--dark:#0a66c2;--light:#ffffffe6 class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"/></svg></a><a href=https://github.com/gracefullight target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=GitHub><svg xmlns=http://www.w3.org/2000/svg width=1em height=1em viewBox="0 0 256 250" preserveAspectRatio=xMidYMid style=--dark:#000;--light:#fff class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"/></svg></a><a href=mailto:gracefullight.dev@gmail.com target=_blank rel="noopener noreferrer" class=authorSocialLink_owbf title=Email><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 24 24" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 class=authorSocialIcon_XYv3><path stroke=none d="M0 0h24v24H0z"/><path d="M7.2 12a4.8 4.8 0 1 0 9.6 0 4.8 4.8 0 1 0-9.6 0"/><path d="M16.8 12v1.8a3 3 0 0 0 6 0V12a10.8 10.8 0 1 0-6.6 9.936"/></svg></a></div></div></div></div></div></header><div class=markdown><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=terminology>Terminology<a href=#terminology class=hash-link aria-label="Terminology에 대한 직접 링크" title="Terminology에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Software: A set of statements written in a programming language to perform tasks</li>
<li class="">Statement: A single instruction in a program that performs an action when executed.</li>
<li class="">Snippet: A block of statements.</li>
<li class="">Software Development: The process of creating a software program.</li>
<li class="">OOP: Program composed of interconnected objects at runtime.</li>
<li class="">Expression: An entity-code component of a statement that can be evaluated to produce a value.</li>
<li class="">Assign: The process of storing the result (a value) of one or more expressions.</li>
<li class="">Value: A data item (literal or computed) that is stored in a variable.</li>
<li class="">Compiler: A special program that translates a programming language's source code into machine code.<!-- -->
<ul>
<li class="">Compilers complete the conversion process all at once after changes are made to the code and before the code is executed</li>
</ul>
</li>
<li class="">Interpreter: A computer program that directly executes code without requiring it to be previously compiled into machine language.<!-- -->
<ul>
<li class="">Interpreters complete the conversion process one step at a time while the code is being executed.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=software-development>Software development<a href=#software-development class=hash-link aria-label="Software development에 대한 직접 링크" title="Software development에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Software development process is an iterative approach.</li>
</ul>
<!-- -->
<ul>
<li class="">java<!-- -->
<ul>
<li class=""><code>javac Welcome.java</code>: Compiles the Java source file <code>Welcome.java</code> into class binary file.</li>
<li class=""><code>java Welcome</code>: Executes the Java program <code>Welcome</code>.</li>
</ul>
</li>
<li class="">python<!-- -->
<ul>
<li class=""><code>python welcome.py</code>: Executes the Python script <code>welcome.py</code>.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=oop>OOP<a href=#oop class=hash-link aria-label="OOP에 대한 직접 링크" title="OOP에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class="">Object: An object is a thing, tangible and intangible. An object has fields that contain the data and methods to access and modify the data.</li>
<li class="">Class: A class is an abstract definition of objects. A class is a template of a blueprint that defines what data and methods are included in objects.</li>
<li class="">Method: A block of code grouped together to perform an operation. A method has a <strong>name</strong>, <strong>parameters</strong>, and a <strong>return type</strong>.</li>
<li class="">Field: A field is a data attribute of an object. A field value is exposed using object methods.</li>
<li class="">Organizing code into classes improves modularity, reusability, extendability, and scalability.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=java-vs-python>Java vs Python<a href=#java-vs-python class=hash-link aria-label="Java vs Python에 대한 직접 링크" title="Java vs Python에 대한 직접 링크" translate=no>​</a></h3>
<table><thead><tr><th>Identifier type<th>Java<th>Python<tbody><tr><td>Class<td>Use CamelCase for multi-word classes<td>Use snake_case for multi-word classes<tr><td>Function<td>use verbs or verb phrases<td>use lowercase_with_underscores<tr><td>Procedure<td>use verbs or verb phrases<td>use lowercase_with_underscores<tr><td>Variable<td>camelCase<td>lowercase_with_underscores<tr><td>Constant<td>All uppercase words separated by underscores<td>All uppercase words separated by underscores<tr><td>Package<td>Lowercase words separated by dots<td>Lowercase words separated by underscores</table>
<ul>
<li class="">Java uses the <code>toString()</code> function to return objects' information.</li>
<li class="">Python can refer to attributes directly or use the <code>__str()__</code> function to return objects' information</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=data-types>Data types<a href=#data-types class=hash-link aria-label="Data types에 대한 직접 링크" title="Data types에 대한 직접 링크" translate=no>​</a></h2>
<table><thead><tr><th>Data Type<th>Size<th>Default value<th>Description<tbody><tr><td>byte<td>1 byte<td>0<td>8-bit signed integer<tr><td>short<td>2 bytes<td>0<td>16-bit signed integer<tr><td>int<td>4 bytes<td>0<td>32-bit signed integer<tr><td>long<td>8 bytes<td>0<td>64-bit signed integer<tr><td>float<td>4 bytes<td>0.0f<td>32-bit floating point<tr><td>double<td>8 bytes<td>0.0d<td>64-bit floating point<tr><td>boolean<td>1 bit<td>false<td>true or false<tr><td>char<td>2 bytes<td>'\u0000'<td>16-bit Unicode character</table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=non-primitive-data-types>Non-Primitive Data Types<a href=#non-primitive-data-types class=hash-link aria-label="Non-Primitive Data Types에 대한 직접 링크" title="Non-Primitive Data Types에 대한 직접 링크" translate=no>​</a></h3>
<ul>
<li class="">Non-primitive: Arrays, Classes, Interfaces, and Strings.</li>
<li class="">Non-primitive data types are by default set to <strong>null</strong> in Java, <strong>None</strong> in Python.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=variables>Variables<a href=#variables class=hash-link aria-label="Variables에 대한 직접 링크" title="Variables에 대한 직접 링크" translate=no>​</a></h2>
<ul>
<li class=""><code>Static</code>: enables the variable to be used without creating an object of its defining class.</li>
<li class=""><code>Final</code>: makes the variable unchangeable.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=operators>Operators<a href=#operators class=hash-link aria-label="Operators에 대한 직접 링크" title="Operators에 대한 직접 링크" translate=no>​</a></h2>
<table><thead><tr><th>Operator Category<th>Java<th>Python<tbody><tr><td>Unary<td>expr++ expr--<td><tr><td><td>++expr --expr +expr -expr<td>+expr -expr<tr><td>Arithmetic<td><code>* / &</code><td><code>* / &</code><tr><td><td><code>+ -</code><td><code>+ -</code><tr><td>Relational<td><code>&lt; > &lt;= >=</code><td><code>&lt; > &lt;= >=</code><tr><td><td><code>==  !=</code><td><code>==  !=</code><tr><td>Logical<td><code>! &&</code><td><code>not and</code><tr><td><td>||<td><code>or</code><tr><td>Ternary<td><code>(expr1) ? &lt;expr2> : &lt;expr3></code><td><code>(expr1) if &lt;expr2> then &lt;expr3></code><tr><td>Assignment<td><code>= += -= *= /= %=</code><td><code>= += -= *= /= %= **=</code><tr><td>Identity/Membership<td><td><code>is  is not  in  not in</code></table>
<ul>
<li class="">Java: <code>boolean q = (5 % 2 != 2) ? true : false</code></li>
<li class="">Python: <code>q = True if (5 % 2 != 2) else False</code></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=standard-input>Standard Input<a href=#standard-input class=hash-link aria-label="Standard Input에 대한 직접 링크" title="Standard Input에 대한 직접 링크" translate=no>​</a></h2>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-java codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token keyword" style=color:#00009f>import</span><span class="token plain"> </span><span class="token import namespace" style=opacity:0.7>java</span><span class="token import namespace punctuation" style=opacity:0.7;color:#393A34>.</span><span class="token import namespace" style=opacity:0.7>util</span><span class="token import namespace punctuation" style=opacity:0.7;color:#393A34>.</span><span class="token import class-name">Scanner</span><span class="token punctuation" style=color:#393A34>;</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>public</span><span class="token plain"> </span><span class="token keyword" style=color:#00009f>class</span><span class="token plain"> </span><span class="token class-name">Inputs</span><span class="token plain"> </span><span class="token punctuation" style=color:#393A34>{</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">  </span><span class="token keyword" style=color:#00009f>static</span><span class="token plain"> </span><span class="token class-name">Scanner</span><span class="token plain"> in </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> </span><span class="token keyword" style=color:#00009f>new</span><span class="token plain"> </span><span class="token class-name">Scanner</span><span class="token punctuation" style=color:#393A34>(</span><span class="token class-name">System</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">in</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>;</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">  </span><span class="token keyword" style=color:#00009f>public</span><span class="token plain"> </span><span class="token keyword" style=color:#00009f>static</span><span class="token plain"> </span><span class="token keyword" style=color:#00009f>void</span><span class="token plain"> </span><span class="token function" style=color:#d73a49>main</span><span class="token punctuation" style=color:#393A34>(</span><span class="token class-name">String</span><span class="token punctuation" style=color:#393A34>[</span><span class="token punctuation" style=color:#393A34>]</span><span class="token plain"> args</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"> </span><span class="token punctuation" style=color:#393A34>{</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token class-name">System</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">out</span><span class="token punctuation" style=color:#393A34>.</span><span class="token function" style=color:#d73a49>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token string" style=color:#e3116c>"X = "</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>;</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token keyword" style=color:#00009f>int</span><span class="token plain"> x </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> in</span><span class="token punctuation" style=color:#393A34>.</span><span class="token function" style=color:#d73a49>nextInt</span><span class="token punctuation" style=color:#393A34>(</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>;</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">    </span><span class="token class-name">System</span><span class="token punctuation" style=color:#393A34>.</span><span class="token plain">out</span><span class="token punctuation" style=color:#393A34>.</span><span class="token function" style=color:#d73a49>println</span><span class="token punctuation" style=color:#393A34>(</span><span class="token string" style=color:#e3116c>"x squared = "</span><span class="token plain"> </span><span class="token operator" style=color:#393A34>+</span><span class="token plain"> </span><span class="token class-name">Math</span><span class="token punctuation" style=color:#393A34>.</span><span class="token function" style=color:#d73a49>pow</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">x</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>2</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>;</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">  </span><span class="token punctuation" style=color:#393A34>}</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token punctuation" style=color:#393A34>}</span><br/></span></code></pre></div></div>
<div class="language-py codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-py codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token keyword" style=color:#00009f>import</span><span class="token plain"> sys</span><br/></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">x </span><span class="token operator" style=color:#393A34>=</span><span class="token plain"> </span><span class="token builtin">int</span><span class="token punctuation" style=color:#393A34>(</span><span class="token builtin">input</span><span class="token punctuation" style=color:#393A34>(</span><span class="token string" style=color:#e3116c>"x = "</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token keyword" style=color:#00009f>print</span><span class="token punctuation" style=color:#393A34>(</span><span class="token string" style=color:#e3116c>"x squared = "</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token builtin">pow</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">x</span><span class="token punctuation" style=color:#393A34>,</span><span class="token plain"> </span><span class="token number" style=color:#36acaa>2</span><span class="token punctuation" style=color:#393A34>)</span><span class="token punctuation" style=color:#393A34>)</span><br/></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=string>String<a href=#string class=hash-link aria-label="String에 대한 직접 링크" title="String에 대한 직접 링크" translate=no>​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=string-java>String (java)<a href=#string-java class=hash-link aria-label="String (java)에 대한 직접 링크" title="String (java)에 대한 직접 링크" translate=no>​</a></h3>
<blockquote>
<p>Immutable</p>
</blockquote>
<ul>
<li class=""><code>String s1 = "Hello";</code>: initialize using literal syntax</li>
<li class=""><code>String s2 = new String("Hello");</code>: initialize using a constructor</li>
</ul>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-java codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">s1 </span><span class="token operator" style=color:#393A34>==</span><span class="token plain"> s1 </span><span class="token comment" style=color:#999988;font-style:italic>// false</span><span class="token plain"></span><br/></span><span class=token-line style=color:#393A34><span class="token plain">s1</span><span class="token punctuation" style=color:#393A34>.</span><span class="token function" style=color:#d73a49>equals</span><span class="token punctuation" style=color:#393A34>(</span><span class="token plain">s2</span><span class="token punctuation" style=color:#393A34>)</span><span class="token plain"> </span><span class="token comment" style=color:#999988;font-style:italic>// true</span><br/></span></code></pre></div></div>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=string-format-python>String Format (Python)<a href=#string-format-python class=hash-link aria-label="String Format (Python)에 대한 직접 링크" title="String Format (Python)에 대한 직접 링크" translate=no>​</a></h3>
<table><thead><tr><th>Symbol<th>Meaning<th>Example code<th>Output<tbody><tr><td><code>&lt;</code><td>Left align<td><code>f'[{42:&lt;5}]'</code><td><code>[42   ]</code><tr><td><code>></code><td>Right align<td><code>f'[{42:>5}]'</code><td><code>[   42]</code><tr><td><code>^</code><td>Center align<td><code>f'[{42:^5}]'</code><td><code>[ 42  ]</code><tr><td><code>&lt;</code> with fill char<td>Left align with custom fill<td><code>f'[{42:-&lt;5}]'</code><td><code>[42---]</code><tr><td><code>></code> with fill char<td>Right align with custom fill<td><code>f'[{42:->5}]'</code><td><code>[---42]</code><tr><td><code>^</code> with fill char<td>Center align with custom fill<td><code>f'[{42:->5}]'</code><td><code>[-42--]</code></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=array>Array<a href=#array class=hash-link aria-label="Array에 대한 직접 링크" title="Array에 대한 직접 링크" translate=no>​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=array-java>Array (java)<a href=#array-java class=hash-link aria-label="Array (java)에 대한 직접 링크" title="Array (java)에 대한 직접 링크" translate=no>​</a></h3>
<p><code>int[] x = {2, 4, -1, 11, 3};</code></p>
<ul>
<li class="">Declaration: <code>int[] x</code></li>
<li class="">Instantiation: <code>x = new int[5];</code></li>
<li class="">Initialization: <code>x[0] = 2; x[1] = 4; x[2] = -1;</code></li>
</ul></div><footer class="row docusaurus-mt-lg"><div class=col><b>태그:</b><ul class="tags_jXut padding--none margin-left--sm"><li class=tag_QGVx><a rel=tag class="tag_zVej tagRegular_sFm0" href=/tags/fsd/>fsd</a></ul></div></footer></article><nav class=pagination-nav aria-label="블로그 게시물 목록 탐색"><a class="pagination-nav__link pagination-nav__link--prev" href=/authors/me/authors/8/><div class=pagination-nav__label>이전 페이지</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/authors/me/authors/10/><div class=pagination-nav__label>다음 페이지</div></a></nav></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class=footer__title>Support Me</div><ul class="footer__items clean-list"><li class=footer__item><a href=https://www.buymeacoffee.com/LOUB2kN target=_blank rel="noopener noreferrer" style="cursor: pointer;">
                <img src=https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png style="height: auto !important;width: auto !important;">
              </a></ul></div><div class="theme-layout-footer-column col footer__col"><div class=footer__title>Feeds</div><ul class="footer__items clean-list"><li class=footer__item><a href=https://gracefullight.dev/rss.xml target=_blank rel="noopener noreferrer" class=footer__link-item>RSS<svg width=13.5 height=13.5 aria-label="(opens in new tab)" class=iconExternalLink_nPIU><use href=#theme-svg-external-link /></svg></a><li class=footer__item><a href=https://gracefullight.dev/atom.xml target=_blank rel="noopener noreferrer" class=footer__link-item>Atom<svg width=13.5 height=13.5 aria-label="(opens in new tab)" class=iconExternalLink_nPIU><use href=#theme-svg-external-link /></svg></a></ul></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Copyright © 2016-2026 Eunkwang Shin.</div></div></div></footer></div></body>