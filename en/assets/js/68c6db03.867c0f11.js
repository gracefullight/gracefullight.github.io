"use strict";(self.webpackChunkgracefullight_github_io=self.webpackChunkgracefullight_github_io||[]).push([["57192"],{72854:function(e,n,s){s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>c});var a=s(21785),i=s(65813),t=s(661);let r={title:"IAI +010",date:new Date("2025-10-09T03:19:13.025Z"),description:"Introduction to AI +010",authors:"me",tags:["iai"]},l,o={authorsImageUrls:[void 0]},c=[{value:"Generative AI",id:"generative-ai",level:2},{value:"Historcal context of Gen AI",id:"historcal-context-of-gen-ai",level:3},{value:"Variational Autoencoders, VAEs",id:"variational-autoencoders-vaes",level:2},{value:"VAE Examples",id:"vae-examples",level:3},{value:"Face Generation Example",id:"face-generation-example",level:4},{value:"Anomaly Detection Example",id:"anomaly-detection-example",level:4},{value:"Autoencoder",id:"autoencoder",level:3},{value:"Image Reconstuction Example",id:"image-reconstuction-example",level:4},{value:"Denoising Images",id:"denoising-images",level:4},{value:"Loss function",id:"loss-function",level:3},{value:"Generative Adversarial Network, GAN",id:"generative-adversarial-network-gan",level:2},{value:"Autoregressive Models",id:"autoregressive-models",level:2},{value:"Training Autoregressive Models",id:"training-autoregressive-models",level:3},{value:"Interfence",id:"interfence",level:3}];function d(e){let n={annotation:"annotation",h2:"h2",h3:"h3",h4:"h4",li:"li",math:"math",mermaid:"mermaid",mi:"mi",mo:"mo",mrow:"mrow",msub:"msub",ol:"ol",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"generative-ai",children:"Generative AI"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Gen AI refers to a category of AI models designed to generte new content, synt99hetic data that resembles a given dataset."}),"\n",(0,i.jsx)(n.li,{children:"Gen AI models create new content, including text, images, audio, and video."}),"\n"]}),"\n",(0,i.jsx)(n.mermaid,{value:"graph TB\n  subgraph AI[Artificial Intelligence]\n    subgraph ML[Machine Learning]\n      subgraph DL[Deep Learning]\n        GenAI[Generative AI]\n\n        GenAI --\x3e GAN\n        GenAI --\x3e VAE\n        GenAI --\x3e AutoregressiveModels\n        GenAI --\x3e DiffusionModels\n      end\n    end\n  end"}),"\n",(0,i.jsx)(n.h3,{id:"historcal-context-of-gen-ai",children:"Historcal context of Gen AI"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"1980s: The development of statistical approaches to AI emerged, focusing on probabilistic models"}),"\n",(0,i.jsx)(n.li,{children:"1990s: Hidden Markov Models (HMMs) became popular in speech recognition and sequence generation tasks, making a shift towards using statistical methods in generative processes."}),"\n",(0,i.jsx)(n.li,{children:"1990s-2000s: The resurgence of Neural Networks, with the introduction of deep learning techniques. However, hardware and data limitations hampered progress."}),"\n",(0,i.jsx)(n.li,{children:"2010s: The advent of deep learning algorithms, especially convolutional neural networks (CNNs) and recurrent neural networks (RNNs), transformed the landscape of AI."}),"\n",(0,i.jsx)(n.li,{children:"2013: VAEs were introduced, providing a probabilistic approach to data generation, allowing for smooth latent space interpolation and structure."}),"\n",(0,i.jsx)(n.li,{children:"2014: GANs, a novel framework where two neural networks (a generator and a discriminator) are trained simultaneously, allowing for the generation of highly realistic images and other data types."}),"\n",(0,i.jsx)(n.li,{children:"2015-2020: Generative models began to find applications beyond image synthesis, including text generation, music composition, and even video generation. OpenAI's GPT-2 showcased the potential of transformer-based models for generating coherent text."}),"\n",(0,i.jsxs)(n.li,{children:["2020s: The introduction of larger and more capable models like OpenAI's GPT-3 and subsequent iterations revolutionized natural language processing.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"DALL-E and Stable Diffusion pushed the boundaries of image generation, allowing users to create images from textual descriptions. This sparked creative exploration and practical applications in marketing, art, and design."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Present: The integration of multiple data modalities (text, image, audio) led to the development of models like CLIP and GPT-4, which can understand and generate content across different formats, enhancing the versatility of generative AI."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"variational-autoencoders-vaes",children:"Variational Autoencoders, VAEs"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"VAEs are from the probabilistic approach to build a generative AI model"}),"\n",(0,i.jsx)(n.li,{children:"VAE learns a latent distribution instead of a fixed latent presentation, allowing for the generation of new samples."}),"\n",(0,i.jsxs)(n.li,{children:["Latent space","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"sample from a Gaussian distribution"}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mi,{children:"\u03BC"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\mu"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.625em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"\u03BC"})]})})]})," and ",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mi,{children:"\u03C3"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\sigma"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"\u03C3"})]})})]})," are learned during training"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mi,{children:"z"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"z"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.04398em"},children:"z"})]})})]})," is a new sample from the latent space"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsxs)(n.mrow,{children:[(0,i.jsxs)(n.msub,{children:[(0,i.jsx)(n.mi,{children:"q"}),(0,i.jsx)(n.mi,{children:"\u03D5"})]}),(0,i.jsx)(n.mo,{stretchy:"false",children:"("}),(0,i.jsx)(n.mi,{children:"z"}),(0,i.jsx)(n.mi,{mathvariant:"normal",children:"\u2223"}),(0,i.jsx)(n.mi,{children:"x"}),(0,i.jsx)(n.mo,{stretchy:"false",children:")"})]}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"q_\\phi(z|x)"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"1.0361em",verticalAlign:"-0.2861em"}}),(0,i.jsxs)(n.span,{className:"mord",children:[(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"q"}),(0,i.jsx)(n.span,{className:"msupsub",children:(0,i.jsxs)(n.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(n.span,{className:"vlist-r",children:[(0,i.jsx)(n.span,{className:"vlist",style:{height:"0.3361em"},children:(0,i.jsxs)(n.span,{style:{top:"-2.55em",marginLeft:"-0.0359em",marginRight:"0.05em"},children:[(0,i.jsx)(n.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(n.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(n.span,{className:"mord mathnormal mtight",children:"\u03D5"})})]})}),(0,i.jsx)(n.span,{className:"vlist-s",children:"\u200B"})]}),(0,i.jsx)(n.span,{className:"vlist-r",children:(0,i.jsx)(n.span,{className:"vlist",style:{height:"0.2861em"},children:(0,i.jsx)(n.span,{})})})]})})]}),(0,i.jsx)(n.span,{className:"mopen",children:"("}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.04398em"},children:"z"}),(0,i.jsx)(n.span,{className:"mord",children:"\u2223"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"x"}),(0,i.jsx)(n.span,{className:"mclose",children:")"})]})})]})," is the encoder that maps input data ",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mi,{children:"x"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"x"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"x"})]})})]})," to a distribution over the latent space ",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mi,{children:"z"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"z"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.04398em"},children:"z"})]})})]})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsxs)(n.mrow,{children:[(0,i.jsxs)(n.msub,{children:[(0,i.jsx)(n.mi,{children:"p"}),(0,i.jsx)(n.mi,{children:"\u03B8"})]}),(0,i.jsx)(n.mo,{stretchy:"false",children:"("}),(0,i.jsx)(n.mi,{children:"x"}),(0,i.jsx)(n.mi,{mathvariant:"normal",children:"\u2223"}),(0,i.jsx)(n.mi,{children:"z"}),(0,i.jsx)(n.mo,{stretchy:"false",children:")"})]}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"p_\\theta(x|z)"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,i.jsxs)(n.span,{className:"mord",children:[(0,i.jsx)(n.span,{className:"mord mathnormal",children:"p"}),(0,i.jsx)(n.span,{className:"msupsub",children:(0,i.jsxs)(n.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(n.span,{className:"vlist-r",children:[(0,i.jsx)(n.span,{className:"vlist",style:{height:"0.3361em"},children:(0,i.jsxs)(n.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,i.jsx)(n.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(n.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(n.span,{className:"mord mathnormal mtight",style:{marginRight:"0.02778em"},children:"\u03B8"})})]})}),(0,i.jsx)(n.span,{className:"vlist-s",children:"\u200B"})]}),(0,i.jsx)(n.span,{className:"vlist-r",children:(0,i.jsx)(n.span,{className:"vlist",style:{height:"0.15em"},children:(0,i.jsx)(n.span,{})})})]})})]}),(0,i.jsx)(n.span,{className:"mopen",children:"("}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"x"}),(0,i.jsx)(n.span,{className:"mord",children:"\u2223"}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.04398em"},children:"z"}),(0,i.jsx)(n.span,{className:"mclose",children:")"})]})})]})," is the decoder that maps a latent variable ",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mi,{children:"z"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"z"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.04398em"},children:"z"})]})})]})," back to the data space ",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mi,{children:"x"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"x"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"x"})]})})]})]}),"\n",(0,i.jsx)(n.li,{children:"During training, the model optimizes the reconstruction loss and a regularization term (KL divergence) to ensure the learned latent distribution is close to a prior distribution (usually a standard normal distribution)."}),"\n",(0,i.jsxs)(n.li,{children:["Latent Representation","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Dimensionality Reduction: latent space is typically lower-dimensional than the input space"}),"\n",(0,i.jsx)(n.li,{children:"Smoothness: In a well-structured latent space, similar inputs will be represented by nearby points."}),"\n",(0,i.jsx)(n.li,{children:"Generative Capabilities: Once trained, can sample from the latent space to generate new data that resembles the training set."}),"\n",(0,i.jsx)(n.li,{children:"Regularization: The VAE incorporates a regularization term in its loss function (KL divergence), which encourages the lerned latent distribution to be close to a standard normal distribution."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Decoder","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["The decoder takes the sampled latent representation ",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsx)(n.mrow,{children:(0,i.jsx)(n.mi,{children:"z"})}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"z"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.04398em"},children:"z"})]})})]})," and reconstructs the original input data."]}),"\n",(0,i.jsx)(n.li,{children:"The goal is to make the reconstructed data as close as possible to the original input."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"vae-examples",children:"VAE Examples"}),"\n",(0,i.jsx)(n.h4,{id:"face-generation-example",children:"Face Generation Example"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Trains a VAE on face photos."}),"\n",(0,i.jsx)(n.li,{children:"Latent space learns meaningful features (e.g. hair color, glasses, smile)"}),"\n",(0,i.jsx)(n.li,{children:"By sampling and interpolating in latent space, can generate new faces or smoothly morph one face into another."}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"anomaly-detection-example",children:"Anomaly Detection Example"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Train a VAE on normal sensor data."}),"\n",(0,i.jsx)(n.li,{children:"When fed unusual data, reconstruction error will be high."}),"\n",(0,i.jsx)(n.li,{children:"Use this for fault detection in machines, fraud detction, etc."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"autoencoder",children:"Autoencoder"}),"\n",(0,i.jsx)(n.mermaid,{value:"graph LR\n  InputData[Input Data] --\x3e Encoder[Encoder]\n  Encoder --\x3e LatentSpace((Latent Space))\n  LatentSpace --\x3e Decoder[Decoder]\n  Decoder --\x3e ReconstructedData[Reconstructed Data]"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Encoder","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Input Layer: takes in the original data"}),"\n",(0,i.jsx)(n.li,{children:"Hidden Layer: These layers progrssively reduce the dimensionality of the input through operations like linear transformations and non-linear activations. (e.g., ReLU-Rectified Linear Unit)"}),"\n",(0,i.jsx)(n.li,{children:"Ouput Layer: Produces the final latent represntation. Sometimes Sigmoid or Tanh are used depending on the nature of the input data."}),"\n",(0,i.jsx)(n.li,{children:"Learns to capture meaningful patterns in the data by minimizaing reconstruction loss, which mesures the difference between the original input and the reconstructed output produced by the decoder."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Decoder","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"typically mirrors the structure of the encoder but in reverse."}),"\n",(0,i.jsx)(n.li,{children:"During trainng, Mean squared Error (MSE) for continuous data or Binary Cross-Entropy (BCE) for binary data are commonly used to quantify the reconstruction loss."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"image-reconstuction-example",children:"Image Reconstuction Example"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"input: 28x28 pixel"}),"\n",(0,i.jsx)(n.li,{children:"encoder: compresses it to just 16 numbers (latent vector)"}),"\n",(0,i.jsx)(n.li,{children:"decoder: expands those 16 numbers back into a 28x28 image"}),"\n",(0,i.jsx)(n.li,{children:"result: the reconstructed digit looks similar to the original but not in the training set."}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"denoising-images",children:"Denoising Images"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"input: a noisy photo of a cat"}),"\n",(0,i.jsx)(n.li,{children:"encoder: learns to ignore the noise and compress meaningful features."}),"\n",(0,i.jsx)(n.li,{children:"decoder: rebuilds the image without the noise."}),"\n",(0,i.jsx)(n.li,{children:"output: a clearer cat image."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"loss-function",children:"Loss function"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Reconstruction loss: Ensure output similar to input"}),"\n",(0,i.jsx)(n.li,{children:"KL divergence loss: Push the learned distribution to be close to a standard normal distribution. (can sample new data)"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"generative-adversarial-network-gan",children:"Generative Adversarial Network, GAN"}),"\n",(0,i.jsx)(n.mermaid,{value:"graph LR\n  RandomInput[Random Input z] --\x3e Generator[Generator]\n    Generator --\x3e FakeBatchSamples[Fake Batch Samples Gz]\n\n    FakeBatchSamples --\x3e Discriminator[Discriminator]\n\n  TrainingData[Training Data] --\x3e RealBatchSamples[Real Batch Samples x]\n  RealBatchSamples --\x3e Discriminator\n\n  Discriminator --\x3e Decision[Real or Fake]\n  Decision --\x3e DiscriminatorLoss[Discriminator Loss]\n  Decision --\x3e GeneratorLoss[Generator Loss]\n    DiscriminatorLoss --\x3e Discriminator\n    GeneratorLoss --\x3e Generator"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Generator: Learns to generate fake (generated) data that resembles data distribution."}),"\n",(0,i.jsx)(n.li,{children:"Discriminator: Learns to distinguish between real data and data generated by the Generator."}),"\n",(0,i.jsxs)(n.li,{children:["Steps","\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Generator creates fake data samples fro mrandom input (noise)."}),"\n",(0,i.jsx)(n.li,{children:"Discriminator evaludates these samples together with real data samples."}),"\n",(0,i.jsx)(n.li,{children:"Discriminator outputs probabilities indicatcing whether each sample is real or fake."}),"\n",(0,i.jsx)(n.li,{children:"Based on the prediction of the Discriminator, the Generator and Discriminator are updated using specific loss functions."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Applications","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Labels to Street Scenes"}),"\n",(0,i.jsx)(n.li,{children:"Labels to Facade"}),"\n",(0,i.jsx)(n.li,{children:"BW to Color"}),"\n",(0,i.jsx)(n.li,{children:"Aerial to Map"}),"\n",(0,i.jsx)(n.li,{children:"Day to Nihght"}),"\n",(0,i.jsx)(n.li,{children:"Edges to Photo"}),"\n",(0,i.jsx)(n.li,{children:"Text-to-Image Synthesis"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"autoregressive-models",children:"Autoregressive Models"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"a class of generative models where the current value of a time series is expressed as a linear function of its own past values plus some noise."}),"\n",(0,i.jsx)(n.li,{children:"foundational in generative AI and widely used in generative AI, particularly for tasks like text generation, speech synthesis."}),"\n",(0,i.jsxs)(n.li,{children:["Examples","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"GPT series: state-of-the-art autoregressive language models used for text generation."}),"\n",(0,i.jsx)(n.li,{children:"WaveNet: an autoregressive model for generating high-quality audio by predicting each sample conditioned on previous samples."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"training-autoregressive-models",children:"Training Autoregressive Models"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Pretraining","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"the model sees sequences of tokens and learns to guess the next token."}),"\n",(0,i.jsx)(n.li,{children:"objective: minimize cross-entropy loss between its guess and the true next token."}),"\n",(0,i.jsx)(n.li,{children:"this teaches grammar, facts, reasoning patterns, and style from raw text."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Supervised fine-tuning (optional)","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"smaller curated datasets (questions to answer, instructions to respond) teach it to follow directions."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Reinforcement learning from Human Feedback (optional)","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Humans rank multiple model outputs; a reward model is trained on those rankings; GPT is then optimized to produce higher-reward responses (safer, more helpful, less toxic)"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Text to ",(0,i.jsx)(n.strong,{children:"Tokens"})," via a tokenizer (e.g. BPE, Byte Pair Encoding)"]}),"\n",(0,i.jsxs)(n.li,{children:["Each token becomes a vector (",(0,i.jsx)(n.strong,{children:"Embedding"}),")"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Positional encodings"})," inject order information."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Transformer layer"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"self-attention"}),": each token looks at all previous token (causal mask) and decides which ones matter, computing weighted combinations."]}),"\n",(0,i.jsxs)(n.li,{children:["Multiple ",(0,i.jsx)(n.strong,{children:"heads"})," let it attend to different patterns (syntax, long-range links, etc.)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"feed-forward network"}),": a nonlinear MLP refines each token's representation."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"residual connections & layer norm"})," stabilize tranining."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"interfence",children:"Interfence"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"a prompt (the context)"}),"\n",(0,i.jsx)(n.li,{children:"GPT computes probabiliites for the next token."}),"\n",(0,i.jsxs)(n.li,{children:["A decoding stragety samples a token","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Decoding knobs","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Greedy: take the top token"}),"\n",(0,i.jsx)(n.li,{children:"Top-K"}),"\n",(0,i.jsx)(n.li,{children:"Nucleus (Top-p) sampling (limit to likely options)"}),"\n",(0,i.jsxs)(n.li,{children:["Temperature scales randomness, controls how random the next token choice is","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"lower = more determistic, higher = more creative"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"append the token and repeat autoregressive generation."}),"\n"]})]})}function h(e={}){let{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},661:function(e,n,s){s.d(n,{R:()=>r,x:()=>l});var a=s(59729);let i={},t=a.createContext(i);function r(e){let n=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),a.createElement(t.Provider,{value:n},e.children)}},21785:function(e){e.exports=JSON.parse('{"permalink":"/en/2025/10/09/introduction-to-ai-009","source":"@site/blog/2025/10/09/introduction-to-ai-009.md","title":"IAI +010","description":"Introduction to AI +010","date":"2025-10-09T03:19:13.025Z","tags":[{"inline":true,"label":"iai","permalink":"/en/tags/iai"}],"readingTime":6.52,"hasTruncateMarker":false,"authors":[{"name":"Gracefullight","title":"Owner","url":"https://github.com/gracefullight","imageURL":"https://avatars.githubusercontent.com/u/11773683?v=4","key":"me","page":null}],"frontMatter":{"title":"IAI +010","date":"2025-10-09T03:19:13.025Z","description":"Introduction to AI +010","authors":"me","tags":["iai"]},"unlisted":false,"prevItem":{"title":"Vocabulary for AI 011","permalink":"/en/vocab/vocab-ai-011"},"nextItem":{"title":"FDA +010","permalink":"/en/2025/10/08/fundamentals-of-data-analytics-010"}}')}}]);