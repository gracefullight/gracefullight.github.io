"use strict";(self.webpackChunkgracefullight_github_io=self.webpackChunkgracefullight_github_io||[]).push([["55464"],{84408:function(e,n,i){i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>c});var t=i(98880),s=i(69979),r=i(59338);let o={title:"Octo Review",date:new Date("2025-08-27T10:54:09.447Z"),description:"Octo, An Open-Source Generalist Robot Policy Review",authors:"me",tags:["vlm"]},l=void 0,a={authorsImageUrls:[void 0]},c=[{value:"Octo",id:"octo",level:2},{value:"Motivation",id:"motivation",level:2},{value:"Prior GRPs &amp; Gaps",id:"prior-grps--gaps",level:2},{value:"Contribution (What is Octo?)",id:"contribution-what-is-octo",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Training Data &amp; Objective",id:"training-data--objective",level:2},{value:"Experiments",id:"experiments",level:2},{value:"Results",id:"results",level:2},{value:"Limitations / Future Work",id:"limitations--future-work",level:2},{value:"One-line Takeaway",id:"one-line-takeaway",level:2},{value:"Ref",id:"ref",level:2}];function d(e){let n={br:"br",code:"code",em:"em",h2:"h2",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"octo",children:"Octo"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Octo is a transformer-based policy with modular tokenizers (language via T5, images via CNN patches), blockwise masking, and readout tokens, trained on 800k multi-robot trajectories."}),"\n",(0,s.jsx)(n.li,{children:"Actions are generated through a diffusion head that produces continuous, multimodal, chunked predictions, enabling precise control and broad generalization."}),"\n",(0,s.jsx)(n.li,{children:"It achieves state-of-the-art zero-shot performance across 7 robots and allows efficient finetuning to new sensors and action spaces, while being fully open-source."}),"\n"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Category"}),(0,s.jsx)(n.th,{children:"Simple Analogy"}),(0,s.jsx)(n.th,{children:"Actual Tokenization"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Language"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"[Sentence]"})}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"[l\u2081, l\u2082, l\u2083, \u2026]"})," ",(0,s.jsx)("br",{}),"\u2192 multiple tokens from a tokenized sentence"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Goal Image"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"[Goal]"})}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"[g\u2081, g\u2082, g\u2083, \u2026]"})," ",(0,s.jsx)("br",{}),"\u2192 image split into patches"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Observation (time t)"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"[Observation]"})}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"[o\u209C\xb9, o\u209C\xb2, o\u209C\xb3, \u2026]"})," ",(0,s.jsx)("br",{}),"\u2192 camera frames/sensors tokenized into patches"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Readout Token"})}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"[ ]"})," (empty slot)"]}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"[TR,t]"})," ",(0,s.jsx)("br",{}),"\u2192 one per timestep, reserved for predicting actions"]})]})]})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"Time t-1: [l] [g] [o_{t-1}] [TR,t-1]\nTime t:   [l] [g] [o_t]     [TR,t]\nTime t+1: [l] [g] [o_{t+1}] [TR,t+1]\n\n[TR,t-1], [TR,t], [TR,t+1]  \u2500\u2500\u25BA  Diffusion head  \u2500\u2500\u25BA  [a_t, a_{t+1}, \u2026]\n"})}),"\n",(0,s.jsx)(n.h2,{id:"motivation",children:"Motivation"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Traditional robot learning trains policies ",(0,s.jsx)(n.strong,{children:"from scratch"})," on robot/task-specific datasets \u2192 costly data collection, narrow generalization."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Generalist Robot Policies (GRPs)"})," pretrained on diverse robots/tasks can be ",(0,s.jsx)(n.strong,{children:"finetuned with little in-domain data"})," while generalizing broadly."]}),"\n",(0,s.jsxs)(n.li,{children:["Real-world deployments face challenges across ",(0,s.jsx)(n.strong,{children:"robot embodiments, sensor setups, action spaces, task specs, and environments"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"prior-grps--gaps",children:"Prior GRPs & Gaps"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["GRPs aim for ",(0,s.jsx)(n.strong,{children:"low-level visuomotor control"})," across tasks, environments, and robotic systems."]}),"\n",(0,s.jsxs)(n.li,{children:["Existing models often have ",(0,s.jsx)(n.strong,{children:"restricted inputs (e.g., a single camera)"}),", ",(0,s.jsx)(n.strong,{children:"lack efficient finetuning to new domains"}),", and importantly, ",(0,s.jsx)(n.strong,{children:"largest models are not publicly available"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"contribution-what-is-octo",children:"Contribution (What is Octo?)"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Octo"}),": a large transformer-based policy trained on ",(0,s.jsx)(n.strong,{children:"800k trajectories"})," from the Open X-Embodiment dataset."]}),"\n",(0,s.jsxs)(n.li,{children:["Accepts ",(0,s.jsx)(n.strong,{children:"language instructions or goal images"}),", and can be ",(0,s.jsx)(n.strong,{children:"finetuned within hours on consumer GPUs"})," to new sensors and action spaces."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"First GRP"})," to support ",(0,s.jsx)(n.strong,{children:"effective finetuning to new observations and actions"})," and to be ",(0,s.jsx)(n.strong,{children:"fully open-source"})," (training pipeline, checkpoints, data)."]}),"\n",(0,s.jsxs)(n.li,{children:["Novelty lies in combining: ",(0,s.jsx)(n.strong,{children:"transformer backbone + language/goal image conditioning + diffusion head"})," for expressive action distributions."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input tokenizers"}),":","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Language via pretrained ",(0,s.jsx)(n.strong,{children:"T5-base"})]}),"\n",(0,s.jsx)(n.li,{children:"Images via shallow CNN \u2192 patch tokens"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Transformer backbone"}),": processes unified token sequence."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Blockwise masking + Readout tokens"}),":","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Nonexistent modalities are masked"}),"\n",(0,s.jsxs)(n.li,{children:["Readout tokens ",(0,s.jsx)(n.em,{children:"only attend"})," to past observations/tasks, not vice versa"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Diffusion action head"}),": predicts ",(0,s.jsx)(n.strong,{children:"continuous, multimodal, chunked actions"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Modularity"}),": new sensors/outputs can be added by only training lightweight encoders or heads; pretrained backbone remains unchanged."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Octo Architecture",src:i(87709).Z+"",width:"803",height:"415"})}),"\n",(0,s.jsx)(n.h2,{id:"training-data--objective",children:"Training Data & Objective"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Mixture of ",(0,s.jsx)(n.strong,{children:"25 heterogeneous robot datasets"}),": diverse robots, sensors (with/without wrist cams), labels (with/without language)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Conditional diffusion decoding"})," predicts continuous, multimodal action distributions.","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Transformer runs ",(0,s.jsx)(n.strong,{children:"one forward pass"}),"; denoising steps are contained in the small diffusion head."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"experiments",children:"Experiments"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Evaluated on ",(0,s.jsx)(n.strong,{children:"7 robotic platforms across 4 institutions"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Key questions:","\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Zero-shot multi-robot control?"}),"\n",(0,s.jsx)(n.li,{children:"Do Octo weights improve finetuning vs. scratch or standard pretrained representations?"}),"\n",(0,s.jsx)(n.li,{children:"Which design choices matter for generalist robot policies?"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"results",children:"Results"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Achieves ",(0,s.jsx)(n.strong,{children:"state-of-the-art zero-shot multi-robot control"}),", competitive with RT-1-X and RT-2-X."]}),"\n",(0,s.jsxs)(n.li,{children:["Provides a ",(0,s.jsx)(n.strong,{children:"versatile policy initialization"}),": significantly outperforms baselines for ",(0,s.jsx)(n.strong,{children:"data-efficient finetuning"})," to new obs/action spaces."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"limitations--future-work",children:"Limitations / Future Work"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Needs ",(0,s.jsx)(n.strong,{children:"better language conditioning"}),", ",(0,s.jsx)(n.strong,{children:"improved wrist camera support"}),", and ",(0,s.jsx)(n.strong,{children:"data beyond optimal demonstrations"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"one-line-takeaway",children:"One-line Takeaway"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Octo = modular, efficient, open-source GRP"}),":",(0,s.jsx)(n.br,{}),"\n","A transformer + diffusion policy trained on large-scale multi-robot data that ",(0,s.jsx)(n.strong,{children:"adapts quickly with little in-domain data"})," to new sensors and action spaces, enabling broad generalization."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"ref",children:"Ref"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Mees, O., Ghosh, D., Pertsch, K., Black, K., Walke, H. R., Dasari, S., Hejna, J., Kreiman, T., Xu, C., & Luo, J. (2024). Octo: An open-source generalist robot policy. First Workshop on Vision-Language Models for Navigation and Manipulation at ICRA 2024."}),"\n"]})]})}function h(e={}){let{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},87709:function(e,n,i){i.d(n,{Z:()=>t});let t=i.p+"assets/images/octo-architecture-49b9dd94643695f0566e74ac5a0801bd.png"},59338:function(e,n,i){i.d(n,{Z:()=>l,a:()=>o});var t=i(52136);let s={},r=t.createContext(s);function o(e){let n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(r.Provider,{value:n},e.children)}},98880:function(e){e.exports=JSON.parse('{"permalink":"/2025/08/27/octo-review","source":"@site/blog/2025/08/27/octo-review.md","title":"Octo Review","description":"Octo, An Open-Source Generalist Robot Policy Review","date":"2025-08-27T10:54:09.447Z","tags":[{"inline":true,"label":"vlm","permalink":"/tags/vlm"}],"readingTime":3.14,"hasTruncateMarker":false,"authors":[{"name":"Eunkwang Shin","title":"Owner","url":"https://github.com/gracefullight","socials":{"linkedin":"https://www.linkedin.com/in/gracefullight/","github":"https://github.com/gracefullight"},"description":"Full Stack JavaScript Developer | Half-time Open Sourcerer.","page":{"permalink":"/authors/me"},"imageURL":"https://avatars.githubusercontent.com/u/11773683?v=4","key":"me"}],"frontMatter":{"title":"Octo Review","date":"2025-08-27T10:54:09.447Z","description":"Octo, An Open-Source Generalist Robot Policy Review","authors":"me","tags":["vlm"]},"unlisted":false,"prevItem":{"title":"Logistic regression","permalink":"/2025/08/28/logistic-regression"},"nextItem":{"title":"Introduction to AI @004","permalink":"/2025/08/26/introduction-to-ai-004"}}')}}]);